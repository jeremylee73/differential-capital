{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline psuedo code\n",
    "    n = look back window\n",
    "    k = number of PCs to keep\n",
    "\n",
    "    for each time point t:\n",
    "        p = number of stocks in investable universe at time t\n",
    "        Define an n x p feature matrix X (lagged returns)\n",
    "\n",
    "        Perform PCA on X\n",
    "        Keep the first k PCs in an n x k matrix Z\n",
    "\n",
    "    for each stock s in the investable universe at time t:\n",
    "        Define an n x 1 outcome vector y (future returns of stock s)\n",
    "        Perform a linear regression of y on Z\n",
    "        Predict y for stock s at time t+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = pd.read_pickle(\"./Data/returns.pkl\")\n",
    "returns = returns.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = []\n",
    "\n",
    "for col in returns.columns:\n",
    "    if returns[col].isnull().all() == True:\n",
    "        drop_columns.append(col)\n",
    "        \n",
    "returns.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_investable(t, n):\n",
    "    \"\"\"\"Find stocks in investable universe at time t\n",
    "    (stocks in the S&P500 that have prices recorded for the last n days)\"\"\"\n",
    "    \n",
    "    df_investable = returns.copy(deep = True).sort_index(ascending = False)\n",
    "    \n",
    "    #add 1 date to get the test features in investable\n",
    "    t = t + pd.DateOffset(1)\n",
    "    n += 1\n",
    "    \n",
    "    #if t is now a non-trading day, advance until we reach a valid trading day\n",
    "    while t not in df_investable.index:\n",
    "        t = t + pd.DateOffset(1)\n",
    "    \n",
    "    t_index = df_investable.index.get_loc(t)\n",
    "    \n",
    "    #take n_rows worth of data upto time specified\n",
    "    df_investable = df_investable.iloc[t_index + 1:t_index + n + 1]\n",
    "    \n",
    "    #find all stocks that exist in the S&P at this time period\n",
    "    investable_universe = []\n",
    "    for col in df_investable.columns:\n",
    "        if ~df_investable[col].iloc[:n].isna().any():\n",
    "            investable_universe.append(col)\n",
    "        \n",
    "    df_investable = df_investable[investable_universe]\n",
    "    \n",
    "    return df_investable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_PCA(inv, k):\n",
    "    pca = PCA(n_components = k) \n",
    "    inv_scaled = StandardScaler().fit_transform(inv)   \n",
    "    principal_components = pca.fit_transform(inv_scaled)\n",
    "\n",
    "    df = pd.DataFrame(data = principal_components)\n",
    "    \n",
    "    #For explained variance table\n",
    "    components = pca.components_\n",
    "    component_explained_var = pca.explained_variance_ratio_ * 100\n",
    "    \n",
    "    comp_names = ['PCA' + str(i) for i in range(1, len(component_explained_var) + 1)]\n",
    "\n",
    "    pca_results = pd.DataFrame(data = component_explained_var, index = comp_names)\n",
    "    pca_results.columns = ['Explained variance (%)']\n",
    "    pca_results['Explained variance (%)'] = pca_results['Explained variance (%)'].round(2)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_y(inv, stock, n):\n",
    "    y = inv[[stock]].iloc[:n+1]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X, y):\n",
    "    X_train = X.iloc[1:, :]\n",
    "    X_test = X.iloc[0:1, :]\n",
    "    y_train = y.iloc[1:]\n",
    "    y_test = y.iloc[0:1]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(X_train, y_train):\n",
    "    model = sklearn.ensemble.RandomForestRegressor(n_estimators=200)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model, X_test):\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_returns(t, n, k):\n",
    "    inv = get_investable(t, n)\n",
    "    X = apply_PCA(inv, k)\n",
    "    \n",
    "    returns_t = pd.DataFrame(index = inv.columns, columns = ['Pred', 'Actual'])\n",
    "    \n",
    "    for stock in inv.columns:\n",
    "        y = define_y(inv, stock, n)\n",
    "        X_train, y_train, X_test, y_test = train_test(X, y)\n",
    "        model = model_fit(X_train, y_train)\n",
    "        yhat = model_predict(model, X_test, y_test)[0][0]\n",
    "        returns_t['Pred'].loc[stock] = yhat*100\n",
    "        returns_t['Actual'].loc[stock] = y_test.values[0][0]\n",
    "    \n",
    "    return returns_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_stocks(returns, num_stocks):\n",
    "    pred_returns = returns.sort_values(by = 'Pred', ascending = False)\n",
    "    topn = pred_returns.head(num_stocks)\n",
    "    botn = pred_returns.tail(num_stocks)\n",
    "    \n",
    "    return topn, botn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_return(topn, botn, returns):\n",
    "    return_t = topn['Actual'].mean() - botn['Actual'].mean()\n",
    "    \n",
    "    return return_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(n, k, num_stocks):\n",
    "\n",
    "    time_range = returns.loc['2007':'2021'].index\n",
    "    \n",
    "    portfolio = pd.DataFrame(index = time_range, columns = ['Portfolio Return'])\n",
    "    \n",
    "    count = 0\n",
    "    for t in time_range:\n",
    "        pred_actual = predict_returns(t, n, k)\n",
    "        topn, botn = rank_stocks(pred_actual, num_stocks)\n",
    "        return_t = portfolio_return(topn, botn, pred_actual)\n",
    "        portfolio['Portfolio Return'].loc[t] = return_t\n",
    "        count +=1\n",
    "        print(f'{(count/len(time_range))*100:.2f}% complete')\n",
    "    \n",
    "    return portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03% complete\n",
      "0.06% complete\n",
      "0.08% complete\n",
      "0.11% complete\n",
      "0.14% complete\n",
      "0.17% complete\n",
      "0.19% complete\n",
      "0.22% complete\n",
      "0.25% complete\n",
      "0.28% complete\n",
      "0.30% complete\n",
      "0.33% complete\n",
      "0.36% complete\n",
      "0.39% complete\n",
      "0.41% complete\n",
      "0.44% complete\n",
      "0.47% complete\n",
      "0.50% complete\n",
      "0.52% complete\n",
      "0.55% complete\n",
      "0.58% complete\n",
      "0.61% complete\n",
      "0.63% complete\n",
      "0.66% complete\n",
      "0.69% complete\n",
      "0.72% complete\n",
      "0.74% complete\n",
      "0.77% complete\n",
      "0.80% complete\n",
      "0.83% complete\n",
      "0.85% complete\n",
      "0.88% complete\n",
      "0.91% complete\n",
      "0.94% complete\n",
      "0.96% complete\n",
      "0.99% complete\n",
      "1.02% complete\n",
      "1.05% complete\n",
      "1.08% complete\n",
      "1.10% complete\n",
      "1.13% complete\n",
      "1.16% complete\n",
      "1.19% complete\n",
      "1.21% complete\n",
      "1.24% complete\n",
      "1.27% complete\n",
      "1.30% complete\n",
      "1.32% complete\n",
      "1.35% complete\n",
      "1.38% complete\n",
      "1.41% complete\n",
      "1.43% complete\n",
      "1.46% complete\n",
      "1.49% complete\n",
      "1.52% complete\n",
      "1.54% complete\n",
      "1.57% complete\n",
      "1.60% complete\n",
      "1.63% complete\n",
      "1.65% complete\n",
      "1.68% complete\n",
      "1.71% complete\n",
      "1.74% complete\n",
      "1.76% complete\n",
      "1.79% complete\n",
      "1.82% complete\n",
      "1.85% complete\n",
      "1.87% complete\n",
      "1.90% complete\n",
      "1.93% complete\n",
      "1.96% complete\n",
      "1.99% complete\n",
      "2.01% complete\n",
      "2.04% complete\n",
      "2.07% complete\n",
      "2.10% complete\n",
      "2.12% complete\n",
      "2.15% complete\n",
      "2.18% complete\n",
      "2.21% complete\n",
      "2.23% complete\n",
      "2.26% complete\n",
      "2.29% complete\n",
      "2.32% complete\n",
      "2.34% complete\n",
      "2.37% complete\n",
      "2.40% complete\n",
      "2.43% complete\n",
      "2.45% complete\n",
      "2.48% complete\n",
      "2.51% complete\n",
      "2.54% complete\n",
      "2.56% complete\n",
      "2.59% complete\n",
      "2.62% complete\n",
      "2.65% complete\n",
      "2.67% complete\n",
      "2.70% complete\n",
      "2.73% complete\n",
      "2.76% complete\n",
      "2.78% complete\n",
      "2.81% complete\n",
      "2.84% complete\n",
      "2.87% complete\n",
      "2.89% complete\n",
      "2.92% complete\n",
      "2.95% complete\n",
      "2.98% complete\n",
      "3.01% complete\n",
      "3.03% complete\n",
      "3.06% complete\n",
      "3.09% complete\n",
      "3.12% complete\n",
      "3.14% complete\n",
      "3.17% complete\n",
      "3.20% complete\n"
     ]
    }
   ],
   "source": [
    "portfolio = pipeline(200, 20, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
