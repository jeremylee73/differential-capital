{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, UpSampling1D, BatchNormalization, LSTM, RepeatVector\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import model_from_json\n",
    "from tensorflow import keras\n",
    "from keras import regularizers\n",
    "import datetime\n",
    "import time\n",
    "import requests as req\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from tqdm import tqdm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.compat.v1\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(\"../Data/returns.pkl\").iloc[1:]\n",
    "\n",
    "drop_columns = []\n",
    "for col in df1.columns:\n",
    "    if df1[col].isnull().all() == True:\n",
    "        drop_columns.append(col)\n",
    "        \n",
    "df1.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_investable(t, n_rows):\n",
    "    \"Find stocks in investable universe at time t\\\n",
    "    (stocks in the S&P500 that have prices recorded for the last n_rows days)\"\n",
    "    \n",
    "    df_investable = df1.copy(deep = True).sort_index(ascending = False)\n",
    "    \n",
    "    #add 1 date to get the test features in investable\n",
    "    t = t + pd.DateOffset(1)\n",
    "    \n",
    "    #if t is now a non-trading day, advance until we reach a valid trading day\n",
    "    while t not in df_investable.index:\n",
    "        t = t + pd.DateOffset(1)\n",
    "    \n",
    "    t_index = df_investable.index.get_loc(t)\n",
    "    \n",
    "    #take n_rows worth of data upto time specified\n",
    "    df_investable = df_investable.iloc[t_index + 1:t_index + n_rows + 1]\n",
    "    \n",
    "    #find all stocks that exist in the S&P at this time period\n",
    "    investable_universe = []\n",
    "    for col in df_investable.columns:\n",
    "        if ~df_investable[col].iloc[:n_rows].isna().any():\n",
    "            investable_universe.append(col)\n",
    "        \n",
    "    df_investable = df_investable[investable_universe]\n",
    "    \n",
    "    return df_investable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = get_investable(pd.to_datetime('2018-05-11'),500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts = train_test_split(df1, test_size=0.2, shuffle=False)\n",
    "train = tts[0]\n",
    "test = tts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(train)\n",
    "test_set_scaled = sc.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/250\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.2971 - acc: 0.0000e+00 - val_loss: 0.2824 - val_acc: 0.0000e+00\n",
      "Epoch 2/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2778 - acc: 0.0000e+00 - val_loss: 0.2725 - val_acc: 0.0000e+00\n",
      "Epoch 3/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2677 - acc: 0.0000e+00 - val_loss: 0.2680 - val_acc: 0.0000e+00\n",
      "Epoch 4/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2630 - acc: 0.0000e+00 - val_loss: 0.2629 - val_acc: 0.0000e+00\n",
      "Epoch 5/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2580 - acc: 0.0000e+00 - val_loss: 0.2551 - val_acc: 0.0000e+00\n",
      "Epoch 6/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2503 - acc: 0.0000e+00 - val_loss: 0.2455 - val_acc: 0.0000e+00\n",
      "Epoch 7/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2408 - acc: 0.0000e+00 - val_loss: 0.2352 - val_acc: 0.0000e+00\n",
      "Epoch 8/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2307 - acc: 0.0000e+00 - val_loss: 0.2247 - val_acc: 0.0000e+00\n",
      "Epoch 9/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2204 - acc: 0.0000e+00 - val_loss: 0.2144 - val_acc: 0.0000e+00\n",
      "Epoch 10/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2102 - acc: 0.0000e+00 - val_loss: 0.2042 - val_acc: 0.0000e+00\n",
      "Epoch 11/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2002 - acc: 0.0000e+00 - val_loss: 0.1942 - val_acc: 0.0000e+00\n",
      "Epoch 12/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1903 - acc: 0.0000e+00 - val_loss: 0.1841 - val_acc: 0.0000e+00\n",
      "Epoch 13/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1804 - acc: 0.0000e+00 - val_loss: 0.1740 - val_acc: 0.0000e+00\n",
      "Epoch 14/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1703 - acc: 0.0000e+00 - val_loss: 0.1638 - val_acc: 0.0000e+00\n",
      "Epoch 15/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1602 - acc: 0.0000e+00 - val_loss: 0.1536 - val_acc: 0.0000e+00\n",
      "Epoch 16/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1500 - acc: 0.0000e+00 - val_loss: 0.1435 - val_acc: 0.0000e+00\n",
      "Epoch 17/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1400 - acc: 0.0000e+00 - val_loss: 0.1338 - val_acc: 0.0000e+00\n",
      "Epoch 18/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1303 - acc: 0.0000e+00 - val_loss: 0.1244 - val_acc: 0.0000e+00\n",
      "Epoch 19/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1210 - acc: 0.0031 - val_loss: 0.1153 - val_acc: 0.0000e+00\n",
      "Epoch 20/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1120 - acc: 0.0031 - val_loss: 0.1067 - val_acc: 0.0000e+00\n",
      "Epoch 21/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1034 - acc: 0.0000e+00 - val_loss: 0.0984 - val_acc: 0.0000e+00\n",
      "Epoch 22/250\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0952 - acc: 0.0000e+00 - val_loss: 0.0905 - val_acc: 0.0000e+00\n",
      "Epoch 23/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0874 - acc: 0.0000e+00 - val_loss: 0.0831 - val_acc: 0.0000e+00\n",
      "Epoch 24/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0801 - acc: 0.0000e+00 - val_loss: 0.0761 - val_acc: 0.0000e+00\n",
      "Epoch 25/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0732 - acc: 0.0000e+00 - val_loss: 0.0696 - val_acc: 0.0000e+00\n",
      "Epoch 26/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0667 - acc: 0.0000e+00 - val_loss: 0.0636 - val_acc: 0.0000e+00\n",
      "Epoch 27/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0608 - acc: 0.0000e+00 - val_loss: 0.0580 - val_acc: 0.0000e+00\n",
      "Epoch 28/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0553 - acc: 0.0000e+00 - val_loss: 0.0530 - val_acc: 0.0000e+00\n",
      "Epoch 29/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0503 - acc: 0.0000e+00 - val_loss: 0.0483 - val_acc: 0.0000e+00\n",
      "Epoch 30/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0457 - acc: 0.0000e+00 - val_loss: 0.0442 - val_acc: 0.0000e+00\n",
      "Epoch 31/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0416 - acc: 0.0000e+00 - val_loss: 0.0404 - val_acc: 0.0125\n",
      "Epoch 32/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0378 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0125\n",
      "Epoch 33/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0345 - acc: 0.0094 - val_loss: 0.0340 - val_acc: 0.0125\n",
      "Epoch 34/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0315 - acc: 0.0094 - val_loss: 0.0313 - val_acc: 0.0125\n",
      "Epoch 35/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0289 - acc: 0.0094 - val_loss: 0.0289 - val_acc: 0.0125\n",
      "Epoch 36/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0265 - acc: 0.0094 - val_loss: 0.0268 - val_acc: 0.0125\n",
      "Epoch 37/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0244 - acc: 0.0094 - val_loss: 0.0249 - val_acc: 0.0125\n",
      "Epoch 38/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0226 - acc: 0.0094 - val_loss: 0.0233 - val_acc: 0.0125\n",
      "Epoch 39/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0210 - acc: 0.0094 - val_loss: 0.0219 - val_acc: 0.0000e+00\n",
      "Epoch 40/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0196 - acc: 0.0094 - val_loss: 0.0207 - val_acc: 0.0000e+00\n",
      "Epoch 41/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0184 - acc: 0.0125 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
      "Epoch 42/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0173 - acc: 0.0125 - val_loss: 0.0186 - val_acc: 0.0000e+00\n",
      "Epoch 43/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0178 - val_acc: 0.0000e+00\n",
      "Epoch 44/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0171 - val_acc: 0.0000e+00\n",
      "Epoch 45/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0149 - acc: 0.0125 - val_loss: 0.0164 - val_acc: 0.0000e+00\n",
      "Epoch 46/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0143 - acc: 0.0125 - val_loss: 0.0159 - val_acc: 0.0000e+00\n",
      "Epoch 47/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0137 - acc: 0.0125 - val_loss: 0.0154 - val_acc: 0.0000e+00\n",
      "Epoch 48/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0133 - acc: 0.0125 - val_loss: 0.0150 - val_acc: 0.0000e+00\n",
      "Epoch 49/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0129 - acc: 0.0125 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
      "Epoch 50/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0125 - acc: 0.0125 - val_loss: 0.0143 - val_acc: 0.0000e+00\n",
      "Epoch 51/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0122 - acc: 0.0125 - val_loss: 0.0140 - val_acc: 0.0000e+00\n",
      "Epoch 52/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0119 - acc: 0.0125 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
      "Epoch 53/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0117 - acc: 0.0188 - val_loss: 0.0136 - val_acc: 0.0250\n",
      "Epoch 54/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0115 - acc: 0.0500 - val_loss: 0.0134 - val_acc: 0.1000\n",
      "Epoch 55/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0113 - acc: 0.1125 - val_loss: 0.0132 - val_acc: 0.1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/250\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0111 - acc: 0.1562 - val_loss: 0.0131 - val_acc: 0.1500\n",
      "Epoch 57/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0110 - acc: 0.1875 - val_loss: 0.0129 - val_acc: 0.1500\n",
      "Epoch 58/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0108 - acc: 0.1875 - val_loss: 0.0128 - val_acc: 0.1500\n",
      "Epoch 59/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0107 - acc: 0.1875 - val_loss: 0.0127 - val_acc: 0.1500\n",
      "Epoch 60/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0106 - acc: 0.1875 - val_loss: 0.0127 - val_acc: 0.1500\n",
      "Epoch 61/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0105 - acc: 0.1875 - val_loss: 0.0126 - val_acc: 0.1500\n",
      "Epoch 62/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0105 - acc: 0.1875 - val_loss: 0.0125 - val_acc: 0.1500\n",
      "Epoch 63/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0104 - acc: 0.1875 - val_loss: 0.0124 - val_acc: 0.1500\n",
      "Epoch 64/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0103 - acc: 0.1875 - val_loss: 0.0124 - val_acc: 0.1500\n",
      "Epoch 65/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0103 - acc: 0.1875 - val_loss: 0.0123 - val_acc: 0.1500\n",
      "Epoch 66/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0102 - acc: 0.1875 - val_loss: 0.0123 - val_acc: 0.1500\n",
      "Epoch 67/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0102 - acc: 0.1875 - val_loss: 0.0123 - val_acc: 0.1500\n",
      "Epoch 68/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0101 - acc: 0.1875 - val_loss: 0.0122 - val_acc: 0.1500\n",
      "Epoch 69/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0101 - acc: 0.1875 - val_loss: 0.0122 - val_acc: 0.1500\n",
      "Epoch 70/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0100 - acc: 0.1875 - val_loss: 0.0121 - val_acc: 0.1500\n",
      "Epoch 71/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0100 - acc: 0.1875 - val_loss: 0.0121 - val_acc: 0.1500\n",
      "Epoch 72/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0100 - acc: 0.1875 - val_loss: 0.0121 - val_acc: 0.1500\n",
      "Epoch 73/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0099 - acc: 0.1875 - val_loss: 0.0121 - val_acc: 0.1500\n",
      "Epoch 74/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0099 - acc: 0.1875 - val_loss: 0.0120 - val_acc: 0.1500\n",
      "Epoch 75/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0099 - acc: 0.1875 - val_loss: 0.0120 - val_acc: 0.1500\n",
      "Epoch 76/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0099 - acc: 0.1875 - val_loss: 0.0120 - val_acc: 0.1500\n",
      "Epoch 77/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0098 - acc: 0.1875 - val_loss: 0.0120 - val_acc: 0.1500\n",
      "Epoch 78/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0098 - acc: 0.1875 - val_loss: 0.0119 - val_acc: 0.1500\n",
      "Epoch 79/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0098 - acc: 0.1875 - val_loss: 0.0119 - val_acc: 0.1500\n",
      "Epoch 80/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0098 - acc: 0.1875 - val_loss: 0.0119 - val_acc: 0.1500\n",
      "Epoch 81/250\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0098 - acc: 0.1875 - val_loss: 0.0119 - val_acc: 0.1500\n",
      "Epoch 82/250\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0097 - acc: 0.1875 - val_loss: 0.0119 - val_acc: 0.1500\n",
      "Epoch 83/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0097 - acc: 0.1875 - val_loss: 0.0119 - val_acc: 0.1500\n",
      "Epoch 84/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0097 - acc: 0.1875 - val_loss: 0.0119 - val_acc: 0.1500\n",
      "Epoch 85/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0097 - acc: 0.1875 - val_loss: 0.0119 - val_acc: 0.1500\n",
      "Epoch 86/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0097 - acc: 0.1875 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 87/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0097 - acc: 0.1875 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 88/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0097 - acc: 0.1875 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 89/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0096 - acc: 0.1875 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 90/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0096 - acc: 0.1875 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 91/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0096 - acc: 0.1875 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 92/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0096 - acc: 0.1844 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 93/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0096 - acc: 0.1844 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 94/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0096 - acc: 0.1844 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 95/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0096 - acc: 0.1844 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 96/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0096 - acc: 0.1844 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 97/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0096 - acc: 0.1844 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 98/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0096 - acc: 0.1844 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 99/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0096 - acc: 0.1844 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 100/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0096 - acc: 0.1844 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 101/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 102/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 103/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0118 - val_acc: 0.1500\n",
      "Epoch 104/250\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 105/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 106/250\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 107/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 108/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 109/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 110/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 111/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 112/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 113/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 114/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0095 - acc: 0.1844 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 115/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0094 - acc: 0.1844 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 116/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0094 - acc: 0.1844 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 117/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0094 - acc: 0.1813 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 118/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0094 - acc: 0.1813 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 119/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0094 - acc: 0.1813 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 120/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0094 - acc: 0.1813 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 121/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0094 - acc: 0.1813 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 122/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0094 - acc: 0.1813 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 123/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0094 - acc: 0.1813 - val_loss: 0.0117 - val_acc: 0.1500\n",
      "Epoch 124/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0094 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 125/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0094 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 126/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0094 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 127/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0094 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 128/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0093 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 129/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0093 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 130/250\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0093 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 131/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0093 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 132/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0093 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 133/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0093 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 134/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0093 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 135/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0093 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 136/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0093 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 137/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0093 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 138/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0093 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 139/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0092 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 140/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0092 - acc: 0.1813 - val_loss: 0.0116 - val_acc: 0.1500\n",
      "Epoch 141/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0092 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 142/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0092 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 143/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0092 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 144/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0092 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 145/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0092 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 146/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0092 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 147/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0092 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 148/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0092 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 149/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0092 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 150/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0091 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 151/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0091 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 152/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0091 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 153/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0091 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 154/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0091 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 155/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0091 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 156/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0091 - acc: 0.1813 - val_loss: 0.0115 - val_acc: 0.1500\n",
      "Epoch 157/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0091 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 158/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0091 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 159/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0091 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 160/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0091 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 161/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0090 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 162/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0090 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 163/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0090 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 164/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0090 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 165/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0090 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 166/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0090 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 167/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0090 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 168/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0090 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 169/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0090 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 170/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0090 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 171/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0090 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 172/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0089 - acc: 0.1813 - val_loss: 0.0114 - val_acc: 0.1500\n",
      "Epoch 173/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0089 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 174/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0089 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 175/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0089 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 176/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0089 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 177/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0089 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 178/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0089 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 179/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0089 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 180/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0089 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 181/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0089 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 182/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0088 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 183/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0088 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 184/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0088 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 185/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0088 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 186/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0088 - acc: 0.1813 - val_loss: 0.0113 - val_acc: 0.1500\n",
      "Epoch 187/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0088 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 188/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0088 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 189/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0088 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 190/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0088 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 191/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0088 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 192/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0088 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 193/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 194/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 195/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 196/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 197/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 198/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 199/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 200/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 201/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0112 - val_acc: 0.1500\n",
      "Epoch 202/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 203/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 204/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 205/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 206/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 207/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0087 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 208/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 209/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 210/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 211/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 212/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 213/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 214/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 215/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 216/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 217/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 218/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 219/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 220/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 221/250\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 222/250\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 223/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0111 - val_acc: 0.1500\n",
      "Epoch 224/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 225/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 226/250\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 227/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 228/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0086 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 229/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 230/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 231/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 232/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 233/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 234/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 235/250\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 236/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 237/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 238/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 239/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 240/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 241/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 242/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 243/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 244/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 245/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 246/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 247/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 248/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 249/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0110 - val_acc: 0.1500\n",
      "Epoch 250/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0085 - acc: 0.1813 - val_loss: 0.0109 - val_acc: 0.1500\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# calculated log returns (i.e. the log of the difference between the price x+1 and price x)\n",
    "# windows of train.shape[1] consecutive returns will be produced. \n",
    "# normalized with a MinMaxScaler to the range [0,1].\n",
    "\n",
    "epochs = 250\n",
    "batch_size = 1024\n",
    "\n",
    "class simple_autoencoder():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def reduced_dim(self):\n",
    "        encoding_dim = 20\n",
    "        window_length = training_set_scaled.shape[1]\n",
    "        input_window = Input(shape=(window_length,))\n",
    "        # encoded representation of the input\n",
    "        encoded = Dense(encoding_dim, activation='tanh')(input_window) #tanh, linear, leakyrelu\n",
    "        # model mapping an input to its encoded representation\n",
    "        encoder = Model(input_window, encoded)\n",
    "        return pd.DataFrame(encoder.predict(test_set_scaled)).head()\n",
    "\n",
    "    def model(self,optimizer = \"Adam\", score = 'acc', loss = \"mean_squared_error\", epochs = 250):\n",
    "        encoding_dim = 20\n",
    "        window_length = training_set_scaled.shape[1]\n",
    "        # input placeholder\n",
    "        input_window = Input(shape=(window_length,))\n",
    "        # encoded representation of the input\n",
    "        encoded = Dense(encoding_dim, activation='tanh')(input_window) #tanh, linear, leakyrelu\n",
    "        # lossy reconstruction of the input\n",
    "        decoded = Dense(window_length, activation='linear')(encoded) #linear\n",
    "        # model mapping an input to its reconstruction\n",
    "        simple_autoencoder = Model(input_window, decoded)\n",
    "        simple_autoencoder.summary()\n",
    "        sae = simple_autoencoder.compile(optimizer=optimizer, loss=loss, metrics=score) #MSE\n",
    "        return simple_autoencoder\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=5, mode='auto', verbose = 1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\",save_best_only=True)\n",
    "\n",
    "\n",
    "model = simple_autoencoder()\n",
    "history = model.model().fit(training_set_scaled, training_set_scaled,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_split = 0.2,\n",
    "                    callbacks = [monitor, checkpointer])       \n",
    "#                   validation_data=(test_set_scaled, test_set_scaled))\n",
    "\n",
    "decoded_stocks = simple_autoencoder().model().predict(test_set_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.437074</td>\n",
       "      <td>0.227231</td>\n",
       "      <td>0.315370</td>\n",
       "      <td>-0.179371</td>\n",
       "      <td>-0.223725</td>\n",
       "      <td>0.742912</td>\n",
       "      <td>-0.612623</td>\n",
       "      <td>-0.451722</td>\n",
       "      <td>-0.641005</td>\n",
       "      <td>-0.409083</td>\n",
       "      <td>0.022011</td>\n",
       "      <td>0.553187</td>\n",
       "      <td>-0.564507</td>\n",
       "      <td>0.540361</td>\n",
       "      <td>0.064494</td>\n",
       "      <td>0.752995</td>\n",
       "      <td>0.850209</td>\n",
       "      <td>0.439468</td>\n",
       "      <td>0.634290</td>\n",
       "      <td>0.896585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.642054</td>\n",
       "      <td>-0.058564</td>\n",
       "      <td>0.208198</td>\n",
       "      <td>-0.494163</td>\n",
       "      <td>0.064622</td>\n",
       "      <td>0.785589</td>\n",
       "      <td>-0.746214</td>\n",
       "      <td>-0.434295</td>\n",
       "      <td>-0.617953</td>\n",
       "      <td>-0.196718</td>\n",
       "      <td>-0.113975</td>\n",
       "      <td>0.705459</td>\n",
       "      <td>-0.870010</td>\n",
       "      <td>0.617503</td>\n",
       "      <td>-0.009667</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>0.885976</td>\n",
       "      <td>0.144337</td>\n",
       "      <td>0.689115</td>\n",
       "      <td>0.925327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.676007</td>\n",
       "      <td>-0.375362</td>\n",
       "      <td>0.141359</td>\n",
       "      <td>-0.592122</td>\n",
       "      <td>0.013872</td>\n",
       "      <td>0.829493</td>\n",
       "      <td>-0.850943</td>\n",
       "      <td>-0.583583</td>\n",
       "      <td>-0.645112</td>\n",
       "      <td>-0.527546</td>\n",
       "      <td>-0.176264</td>\n",
       "      <td>0.619092</td>\n",
       "      <td>-0.855205</td>\n",
       "      <td>0.633699</td>\n",
       "      <td>-0.177970</td>\n",
       "      <td>0.559233</td>\n",
       "      <td>0.941178</td>\n",
       "      <td>0.273580</td>\n",
       "      <td>0.766226</td>\n",
       "      <td>0.862093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.452628</td>\n",
       "      <td>-0.141964</td>\n",
       "      <td>0.079891</td>\n",
       "      <td>-0.238992</td>\n",
       "      <td>0.048023</td>\n",
       "      <td>0.764176</td>\n",
       "      <td>-0.823830</td>\n",
       "      <td>-0.488026</td>\n",
       "      <td>-0.542979</td>\n",
       "      <td>-0.239170</td>\n",
       "      <td>-0.369290</td>\n",
       "      <td>0.491900</td>\n",
       "      <td>-0.772568</td>\n",
       "      <td>0.376228</td>\n",
       "      <td>-0.069010</td>\n",
       "      <td>0.627666</td>\n",
       "      <td>0.752972</td>\n",
       "      <td>0.115890</td>\n",
       "      <td>0.685609</td>\n",
       "      <td>0.848571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.608450</td>\n",
       "      <td>-0.284678</td>\n",
       "      <td>0.240953</td>\n",
       "      <td>-0.377357</td>\n",
       "      <td>0.199698</td>\n",
       "      <td>0.778533</td>\n",
       "      <td>-0.751320</td>\n",
       "      <td>-0.337736</td>\n",
       "      <td>-0.701676</td>\n",
       "      <td>-0.430493</td>\n",
       "      <td>-0.208149</td>\n",
       "      <td>0.713304</td>\n",
       "      <td>-0.859954</td>\n",
       "      <td>0.451350</td>\n",
       "      <td>-0.062007</td>\n",
       "      <td>0.629789</td>\n",
       "      <td>0.827502</td>\n",
       "      <td>0.149691</td>\n",
       "      <td>0.658330</td>\n",
       "      <td>0.800748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.437074  0.227231  0.315370 -0.179371 -0.223725  0.742912 -0.612623   \n",
       "1  0.642054 -0.058564  0.208198 -0.494163  0.064622  0.785589 -0.746214   \n",
       "2  0.676007 -0.375362  0.141359 -0.592122  0.013872  0.829493 -0.850943   \n",
       "3  0.452628 -0.141964  0.079891 -0.238992  0.048023  0.764176 -0.823830   \n",
       "4  0.608450 -0.284678  0.240953 -0.377357  0.199698  0.778533 -0.751320   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0 -0.451722 -0.641005 -0.409083  0.022011  0.553187 -0.564507  0.540361   \n",
       "1 -0.434295 -0.617953 -0.196718 -0.113975  0.705459 -0.870010  0.617503   \n",
       "2 -0.583583 -0.645112 -0.527546 -0.176264  0.619092 -0.855205  0.633699   \n",
       "3 -0.488026 -0.542979 -0.239170 -0.369290  0.491900 -0.772568  0.376228   \n",
       "4 -0.337736 -0.701676 -0.430493 -0.208149  0.713304 -0.859954  0.451350   \n",
       "\n",
       "         14        15        16        17        18        19  \n",
       "0  0.064494  0.752995  0.850209  0.439468  0.634290  0.896585  \n",
       "1 -0.009667  0.727232  0.885976  0.144337  0.689115  0.925327  \n",
       "2 -0.177970  0.559233  0.941178  0.273580  0.766226  0.862093  \n",
       "3 -0.069010  0.627666  0.752972  0.115890  0.685609  0.848571  \n",
       "4 -0.062007  0.629789  0.827502  0.149691  0.658330  0.800748  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_autoencoder().reduced_dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    ax = plt.subplot(1, 4, 1)\n",
    "    plt.plot(history.history[\"loss\"])\n",
    "    plt.title(\"Train loss\")\n",
    "    ax = plt.subplot(1, 4, 2)\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "    plt.title(\"Test loss\")\n",
    "    ax = plt.subplot(1, 4, 3)\n",
    "    plt.plot(history.history[\"val_acc\"])\n",
    "    plt.title(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs Epoch\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_regressor = KerasRegressor(simple_autoencoder().model, verbose=1, batch_size=10, epochs=10)\n",
    "#define the grid search parameters\n",
    "#dimensions = []\n",
    "#dropout = []\n",
    "#batch_size = [10,20]\n",
    "loss = ['mean_squared_error']\n",
    "optimizer = ['Adam', 'SGD', 'RMSprop']\n",
    "epochs = [10, 15, 50, 100]\n",
    "score = ['acc', 'mae','mse','mape']\n",
    "\n",
    "param_grid = dict(optimizer=optimizer,score = score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:278: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2122 - acc: 0.0030 \n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0215 - acc: 0.2027\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0097 - acc: 0.2132\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0094 - acc: 0.1864\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0099 - acc: 0.2089\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0094 - acc: 0.1962\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0096 - acc: 0.2122\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0098 - acc: 0.2140\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0091 - acc: 0.2067\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0089 - acc: 0.1910\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0144 - acc: 0.0875\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2002 - acc: 0.0089 \n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0197 - acc: 0.0150\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0105 - acc: 0.1713\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0104 - acc: 0.1825\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0105 - acc: 0.1897\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0098 - acc: 0.1568\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0094 - acc: 0.1603\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0093 - acc: 0.1351\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0088 - acc: 0.1765\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0088 - acc: 0.1461\n",
      "8/8 [==============================] - 0s 973us/step - loss: 0.0083 - acc: 0.1625\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2174 - acc: 0.0021 \n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0218 - acc: 2.8715e-04\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0117 - acc: 0.1057\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0102 - acc: 0.1939\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0104 - acc: 0.1230\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0104 - acc: 0.1073\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0096 - acc: 0.1729\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0098 - acc: 0.1545\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0093 - acc: 0.1596\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0097 - acc: 0.1446\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0074 - acc: 0.2750\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2195 - acc: 0.0129 \n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0256 - acc: 0.1330\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0111 - acc: 0.1451\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0114 - acc: 0.1587\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0105 - acc: 0.1544\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0102 - acc: 0.1405\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0098 - acc: 0.1134\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0094 - acc: 0.1924\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0094 - acc: 0.1713\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0098 - acc: 0.1549\n",
      "8/8 [==============================] - 0s 952us/step - loss: 0.0069 - acc: 0.2000\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2234 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0220 - acc: 0.0046\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0104 - acc: 0.1858\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0099 - acc: 0.1778\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0093 - acc: 0.1990\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0096 - acc: 0.1715\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0091 - acc: 0.1793\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0088 - acc: 0.1757\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0092 - acc: 0.1391\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0085 - acc: 0.1842\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0110 - acc: 0.1500\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2159 - mae: 0.4110\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0198 - mae: 0.0997\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0096 - mae: 0.0672\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0097 - mae: 0.0676\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0092 - mae: 0.0653\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0091 - mae: 0.0655\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0093 - mae: 0.0657\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0093 - mae: 0.0657\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0088 - mae: 0.0647\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0090 - mae: 0.0646\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0138 - mae: 0.0832\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2153 - mae: 0.4089\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0225 - mae: 0.1071\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0111 - mae: 0.0731\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0105 - mae: 0.0705\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0102 - mae: 0.0696\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0101 - mae: 0.0693\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0100 - mae: 0.0685\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0091 - mae: 0.0651\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0089 - mae: 0.0646\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0089 - mae: 0.0642\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0083 - mae: 0.0621\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.2112 - mae: 0.4040\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0209 - mae: 0.1024\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0107 - mae: 0.0718\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0109 - mae: 0.0719\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0100 - mae: 0.0682\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0102 - mae: 0.0689\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0103 - mae: 0.0694\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0094 - mae: 0.0665\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0092 - mae: 0.0658\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0094 - mae: 0.0657\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0074 - mae: 0.0595\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2060 - mae: 0.3941\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0210 - mae: 0.1023\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0110 - mae: 0.0730\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0114 - mae: 0.0735\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0112 - mae: 0.0729\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0110 - mae: 0.0717\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0102 - mae: 0.0694\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0103 - mae: 0.0701\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0096 - mae: 0.0674\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0095 - mae: 0.0667\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0070 - mae: 0.0568\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2074 - mae: 0.3974\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0193 - mae: 0.0992\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0689\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0685\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0092 - mae: 0.0660\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0091 - mae: 0.0655\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0090 - mae: 0.0648\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0089 - mae: 0.0645\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0085 - mae: 0.0635\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0086 - mae: 0.0635\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0111 - mae: 0.0704\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2057 - mse: 0.2057\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0088 - mse: 0.0088\n",
      "8/8 [==============================] - 0s 985us/step - loss: 0.0132 - mse: 0.0132\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.2123 - mse: 0.2123\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0093 - mse: 0.0093\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.2047 - mse: 0.2047\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0095 - mse: 0.0095\n",
      "8/8 [==============================] - 0s 952us/step - loss: 0.0074 - mse: 0.0074\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2253 - mse: 0.2253\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0255 - mse: 0.0255\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0093 - mse: 0.0093\n",
      "8/8 [==============================] - 0s 986us/step - loss: 0.0071 - mse: 0.0071\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 1ms/step - loss: 0.2010 - mse: 0.2010\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0086 - mse: 0.0086\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2149 - mape: 335968.6132\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0180 - mape: 884628.0682\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0089 - mape: 879025.6705\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0091 - mape: 925103.7121\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0094 - mape: 1041133.8068\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0100 - mape: 1278047.3371\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0086 - mape: 1032419.3352\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0090 - mape: 971989.0625\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - mape: 1099808.2008\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0085 - mape: 953090.6004\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0132 - mape: 1980106.3750\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.2015 - mape: 530607.9678\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0179 - mape: 1289242.9489\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0106 - mape: 1156377.6723\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - mape: 1245353.0284\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0099 - mape: 1352001.1610\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0096 - mape: 1230796.7405\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0097 - mape: 1177575.9659\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0095 - mape: 1225489.4015\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0093 - mape: 1214105.4508\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0090 - mape: 1079537.6098\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0083 - mape: 782744.6250\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2104 - mape: 486607.1061\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0209 - mape: 1304548.1080\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0115 - mape: 1313679.8390\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0113 - mape: 1563168.4129\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0114 - mape: 1343197.0341\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0106 - mape: 1357560.3864\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - mape: 1219867.2879\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0103 - mape: 1348828.4432\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0090 - mape: 1061117.5379\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - mape: 1020348.3049\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0074 - mape: 739271.9375\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.2157 - mape: 393988.2495\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0254 - mape: 1098758.9384\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0121 - mape: 1243672.9621\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0105 - mape: 1270802.0303\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0106 - mape: 1144027.5947\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - mape: 1111434.4044\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0098 - mape: 1124910.9583\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0101 - mape: 1190591.6837\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mape: 1141941.3011\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0095 - mape: 1138114.9261\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0070 - mape: 843536.1250\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2162 - mape: 374176.6922\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0201 - mape: 1305518.1686\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0101 - mape: 954695.1648\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0093 - mape: 971960.9697\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mape: 1013735.4167\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - mape: 1203810.7557\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0094 - mape: 1287692.5720\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0094 - mape: 1319688.6098\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0085 - mape: 992831.4015\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0084 - mape: 988431.6667\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0112 - mape: 1583766.0000\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/keras/wrappers/scikit_learn.py\", line 163, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1158, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 763, in _initialize\n",
      "    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n",
      "  File \"/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3050, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3444, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3279, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:830 train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:813 run_step  *\n",
      "        outputs = model.train_step(data)\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:775 train_step  *\n",
      "        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/keras/engine/compile_utils.py:436 update_state  *\n",
      "        self.build(y_pred, y_true)\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/keras/engine/compile_utils.py:358 build  *\n",
      "        self._metrics = tf.__internal__.nest.map_structure_up_to(y_pred, self._get_metric_objects,\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1374 map_structure_up_to  **\n",
      "        return map_structure_with_tuple_paths_up_to(\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1472 map_structure_with_tuple_paths_up_to\n",
      "        results = [\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1473 <listcomp>\n",
      "        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1376 <lambda>\n",
      "        lambda _, *values: func(*values),  # Discards the path arg.\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/keras/engine/compile_utils.py:482 _get_metric_objects\n",
      "        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/keras/engine/compile_utils.py:482 <listcomp>\n",
      "        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/keras/engine/compile_utils.py:501 _get_metric_object\n",
      "        metric_obj = metrics_mod.get(metric)\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/keras/metrics.py:3639 get\n",
      "        return deserialize(str(identifier))\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/keras/metrics.py:3595 deserialize\n",
      "        return deserialize_keras_object(\n",
      "    /Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/keras/utils/generic_utils.py:698 deserialize_keras_object\n",
      "        raise ValueError(\n",
      "\n",
      "    ValueError: Unknown metric function: cosine. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2975 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2899 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2787 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2725 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2683 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2629 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2599 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2576 - acc: 0.0016\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2502 - acc: 3.8816e-04\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2491 - acc: 0.0025\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2443 - acc: 0.0000e+00\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3011 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2889 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2834 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2776 - acc: 2.8715e-04\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2743 - acc: 9.5087e-04\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2704 - acc: 0.0018\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2665 - acc: 0.0035\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2584 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2557 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2606 - acc: 0.0000e+00\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2595 - acc: 0.0000e+00\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.2965 - acc: 0.0042 \n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2832 - acc: 0.0030\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2789 - acc: 0.0021\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2716 - acc: 0.0094\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2736 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2687 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2628 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2607 - acc: 0.0000e+00\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2602 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2569 - acc: 0.0000e+00\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2531 - acc: 0.0000e+00\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2903 - acc: 0.0025 \n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2758 - acc: 0.0030\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2732 - acc: 0.0028\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2690 - acc: 0.0021\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2705 - acc: 0.0068\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2695 - acc: 0.0012\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2661 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2635 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2563 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2532 - acc: 0.0000e+00\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2505 - acc: 0.0000e+00\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2936 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2799 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2766 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2712 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2669 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2667 - acc: 0.0016\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2551 - acc: 8.2966e-04\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2509 - acc: 3.8816e-04\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2518 - acc: 0.0061\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2517 - acc: 0.0042\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2499 - acc: 0.0000e+00\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.2937 - mae: 0.5059\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2855 - mae: 0.5002\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2793 - mae: 0.4963\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2761 - mae: 0.4938\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2721 - mae: 0.4904\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2682 - mae: 0.4862\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2633 - mae: 0.4810\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2624 - mae: 0.4799\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2607 - mae: 0.4775\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2563 - mae: 0.4724\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2549 - mae: 0.4644\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.2828 - mae: 0.4921\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2797 - mae: 0.4916\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2747 - mae: 0.4886\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2681 - mae: 0.4826\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2656 - mae: 0.4812\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2587 - mae: 0.4740\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2620 - mae: 0.4761\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2556 - mae: 0.4705\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2500 - mae: 0.4637\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2468 - mae: 0.4598\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2500 - mae: 0.4649\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2880 - mae: 0.5004\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2797 - mae: 0.4940\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2739 - mae: 0.4888\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2712 - mae: 0.4875\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2636 - mae: 0.4805\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2647 - mae: 0.4815\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2562 - mae: 0.4736\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2538 - mae: 0.4705\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2539 - mae: 0.4698\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2467 - mae: 0.4610\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2431 - mae: 0.4606\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_37 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.2951 - mae: 0.5040\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2853 - mae: 0.4972\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2841 - mae: 0.4980\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2778 - mae: 0.4920\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2719 - mae: 0.4873\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2699 - mae: 0.4861\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2653 - mae: 0.4818\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2587 - mae: 0.4745\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2597 - mae: 0.4760\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2565 - mae: 0.4732\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2519 - mae: 0.4704\n",
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_38 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2933 - mae: 0.5062\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2818 - mae: 0.4974\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2703 - mae: 0.4883\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2680 - mae: 0.4867\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2602 - mae: 0.4776\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2597 - mae: 0.4777\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2590 - mae: 0.4757\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2490 - mae: 0.4646\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2497 - mae: 0.4652\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2496 - mae: 0.4640\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2508 - mae: 0.4629\n",
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2847 - mse: 0.2847\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2797 - mse: 0.2797\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2726 - mse: 0.2726\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2702 - mse: 0.2702\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2678 - mse: 0.2678\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2617 - mse: 0.2617\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2577 - mse: 0.2577\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2564 - mse: 0.2564\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2536 - mse: 0.2536\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2498 - mse: 0.2498\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2479 - mse: 0.2479\n",
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2965 - mse: 0.2965\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2882 - mse: 0.2882\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2820 - mse: 0.2820\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2733 - mse: 0.2733\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2717 - mse: 0.2717\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2685 - mse: 0.2685\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2636 - mse: 0.2636\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2639 - mse: 0.2639\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2580 - mse: 0.2580\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2486 - mse: 0.2486\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2540 - mse: 0.2540\n",
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2940 - mse: 0.2940\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2794 - mse: 0.2794\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2794 - mse: 0.2794\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2746 - mse: 0.2746\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2644 - mse: 0.2644\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2648 - mse: 0.2648\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2636 - mse: 0.2636\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2627 - mse: 0.2627\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2583 - mse: 0.2583\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2581 - mse: 0.2581\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2514 - mse: 0.2514\n",
      "Model: \"model_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_42 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.2950 - mse: 0.2950\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2818 - mse: 0.2818\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2759 - mse: 0.2759\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2700 - mse: 0.2700\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2722 - mse: 0.2722\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2642 - mse: 0.2642\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2588 - mse: 0.2588\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2607 - mse: 0.2607\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2556 - mse: 0.2556\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2554 - mse: 0.2554\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2497 - mse: 0.2497\n",
      "Model: \"model_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_43 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2885 - mse: 0.2885\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2806 - mse: 0.2806\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2747 - mse: 0.2747\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2706 - mse: 0.2706\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2682 - mse: 0.2682\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2661 - mse: 0.2661\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2591 - mse: 0.2591\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2569 - mse: 0.2569\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2591 - mse: 0.2591\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2532 - mse: 0.2532\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2577 - mse: 0.2577\n",
      "Model: \"model_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.2940 - mape: 233236.0393\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2877 - mape: 209492.2500\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2785 - mape: 175036.7160\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2720 - mape: 194322.6993\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2682 - mape: 195107.2533\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2643 - mape: 168105.2367\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2627 - mape: 183095.1013\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2591 - mape: 194657.0554\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2554 - mape: 179324.0505\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2540 - mape: 184237.2810\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2486 - mape: 362074.9688\n",
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_45 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.2903 - mape: 268279.9048\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2848 - mape: 229059.3949\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2766 - mape: 264920.2666\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2732 - mape: 258656.0701\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2666 - mape: 245541.8731\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2650 - mape: 269480.0303\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2584 - mape: 264386.5710\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2565 - mape: 254003.8776\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2541 - mape: 269846.3906\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2505 - mape: 324743.8068\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2514 - mape: 173232.7812\n",
      "Model: \"model_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_46 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2966 - mape: 263646.5724\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2870 - mape: 196612.7576\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2784 - mape: 268530.5743\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2706 - mape: 225388.9962\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2675 - mape: 233024.2410\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2579 - mape: 235523.4169\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2547 - mape: 269104.8456\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2574 - mape: 239659.9058\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2532 - mape: 260147.2718\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - mape: 200296.0819\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2441 - mape: 166374.0312\n",
      "Model: \"model_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_47 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.2972 - mape: 252767.5672\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2881 - mape: 213925.7140\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2776 - mape: 244600.0194\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2778 - mape: 184644.3333\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2697 - mape: 164523.0471\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2653 - mape: 175494.3783\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2691 - mape: 152993.7835\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2613 - mape: 191424.2637\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2591 - mape: 215579.6051\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2566 - mape: 175868.1832\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2528 - mape: 149833.7188\n",
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_48 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2786 - mape: 169602.4242\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2747 - mape: 188162.8629\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2701 - mape: 163685.0888\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2672 - mape: 159795.0241\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2629 - mape: 190234.6056\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2590 - mape: 201685.0405\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2562 - mape: 198254.2976\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2531 - mape: 224967.7188\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2520 - mape: 224276.9077\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2447 - mape: 217072.2609\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2486 - mape: 311827.6250\n",
      "Model: \"model_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_49 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Model: \"model_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_50 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_51 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Model: \"model_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_52 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Model: \"model_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_53 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_54 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1608 - acc: 0.0124\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0118 - acc: 0.1308\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - acc: 0.2130\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0091 - acc: 0.2084\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0093 - acc: 0.1768\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - acc: 0.1639\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0084 - acc: 0.2029\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0089 - acc: 0.1988\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - acc: 0.1829\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - acc: 0.2054\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0144 - acc: 0.0875\n",
      "Model: \"model_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_55 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1686 - acc: 0.0050 \n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0136 - acc: 0.0092\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - acc: 0.1206\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0098 - acc: 0.1802\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0098 - acc: 0.1670\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0102 - acc: 0.1695\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0104 - acc: 0.1711\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0095 - acc: 0.2109\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0109 - acc: 0.1631\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0105 - acc: 0.1729\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0088 - acc: 0.1625\n",
      "Model: \"model_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_56 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1786 - acc: 0.0100 \n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0146 - acc: 0.0475\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0105 - acc: 0.1507\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0104 - acc: 0.1641\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0098 - acc: 0.1614\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0108 - acc: 0.1659\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0101 - acc: 0.1911\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0099 - acc: 0.1321\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0105 - acc: 0.1277\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - acc: 0.1477\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0078 - acc: 0.2750\n",
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_57 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1675 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0137 - acc: 0.0254\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0106 - acc: 0.1413\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0100 - acc: 0.1915\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0106 - acc: 0.1368\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0100 - acc: 0.1816\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0104 - acc: 0.1706\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0108 - acc: 0.1802\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0100 - acc: 0.1490\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - acc: 0.1534\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 0.2125\n",
      "Model: \"model_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_58 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1841 - acc: 4.9265e-04\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0131 - acc: 0.0614\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0098 - acc: 0.1871\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - acc: 0.1894\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0087 - acc: 0.1927\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0089 - acc: 0.1758\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0094 - acc: 0.1947\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0104 - acc: 0.1710\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0093 - acc: 0.1787\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0091 - acc: 0.1818\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0124 - acc: 0.1500\n",
      "Model: \"model_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_59 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1557 - mae: 0.3239\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0115 - mae: 0.0752\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0660\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0646\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0659\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0090 - mae: 0.0651\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0092 - mae: 0.0663\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0651\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0093 - mae: 0.0662\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0085 - mae: 0.0631\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0129 - mae: 0.0811\n",
      "Model: \"model_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_60 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1749 - mae: 0.3475\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0827\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0109 - mae: 0.0724\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0704\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0691\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0688\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0696\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0721\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0692\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0677\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0084 - mae: 0.0630\n",
      "Model: \"model_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_61 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1785 - mae: 0.3519\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0832\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0111 - mae: 0.0734\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0709\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0721\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0716\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0688\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0703\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0683\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0696\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0075 - mae: 0.0603\n",
      "Model: \"model_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_62 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1772 - mae: 0.3523\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0857\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0111 - mae: 0.0734\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0707\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0706\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0724\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0691\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0674\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0108 - mae: 0.0733\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0683\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0097 - mae: 0.0735\n",
      "Model: \"model_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_63 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1756 - mae: 0.3487\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0130 - mae: 0.0807\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0697\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0674\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0664\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0658\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0669\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0672\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0090 - mae: 0.0660\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0669\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0112 - mae: 0.0707\n",
      "Model: \"model_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_64 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1809 - mse: 0.1809\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0092\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Model: \"model_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_65 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1763 - mse: 0.1763\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0105\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Model: \"model_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_66 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1803 - mse: 0.1803\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Model: \"model_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_67 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.1616 - mse: 0.1616\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0099\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Model: \"model_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_68 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1669 - mse: 0.1669\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Model: \"model_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_69 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.1654 - mape: 479783.7718\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0118 - mape: 901333.0644\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0089 - mape: 909097.1250\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0091 - mape: 974121.3333\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0087 - mape: 909192.0909\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0089 - mape: 981150.5246\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0089 - mape: 913312.1913\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0086 - mape: 862010.4792\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0094 - mape: 1082982.6809\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0085 - mape: 900334.1496\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0121 - mape: 1603908.0000\n",
      "Model: \"model_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_70 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1722 - mape: 475053.5923\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0136 - mape: 1079966.8485\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0105 - mape: 1468644.6970\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mape: 1092432.7633\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0096 - mape: 1139348.5587\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - mape: 1165039.4545\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - mape: 1259506.9261\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - mape: 1264726.5076\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - mape: 1323618.6705\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mape: 1103682.0152\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0084 - mape: 772139.4375\n",
      "Model: \"model_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_71 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.1647 - mape: 579674.0426\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0134 - mape: 1076916.2424\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0106 - mape: 1493339.1705\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0099 - mape: 1149302.4773\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - mape: 1083837.6326\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0106 - mape: 1332308.5152\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0105 - mape: 1286767.0568\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0092 - mape: 997793.7898\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - mape: 1321532.9470\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0096 - mape: 1144269.5568\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0100 - mape: 816035.7500\n",
      "Model: \"model_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_72 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1828 - mape: 563380.8101\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0151 - mape: 1134666.4242\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0113 - mape: 1146901.7652\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0102 - mape: 1076788.6989\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - mape: 1323629.7614\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0109 - mape: 1338538.0606\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0102 - mape: 1117084.7027\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0098 - mape: 1155518.9811\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0100 - mape: 1259970.1212\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0097 - mape: 980159.3201\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0076 - mape: 837744.9375\n",
      "Model: \"model_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_73 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.1779 - mape: 457262.0971\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0138 - mape: 915419.9257\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0097 - mape: 994270.0530\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0090 - mape: 969109.9148\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0088 - mape: 910236.7992\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0093 - mape: 1087174.6326\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0093 - mape: 980366.8684\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0091 - mape: 946354.3939\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0089 - mape: 989653.1193\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - mape: 1004252.2784\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0115 - mape: 1657957.7500\n",
      "Model: \"model_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_74 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Model: \"model_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_75 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Model: \"model_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_76 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Model: \"model_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_77 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Model: \"model_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_78 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Model: \"model_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_79 (InputLayer)        [(None, 644)]             0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 20)                12900     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 644)               13524     \n",
      "=================================================================\n",
      "Total params: 26,424\n",
      "Trainable params: 26,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 1s 2ms/step - loss: 0.1897 - mse: 0.1897\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0092\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(estimator=model_regressor, param_distributions=param_grid, n_iter=100)\n",
    "random_search.fit(training_set_scaled, training_set_scaled)\n",
    "\n",
    "random_best_parameters = random_search.best_params_\n",
    "random_best_accuracy = random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'mse', 'optimizer': 'Adam'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.009380506910383701"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
