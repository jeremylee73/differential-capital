{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, UpSampling1D, BatchNormalization, LSTM, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "from keras import regularizers\n",
    "import datetime\n",
    "import time\n",
    "import requests as req\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USE: full log(returns)/returns dataframe\n",
    "## Risk Adjusted Returns\n",
    "\n",
    "#df = pd.read_pickle(\"../Data/risk_adj_returns.pkl\").iloc[1:]\n",
    "df = pd.read_pickle(\"Data/risk_adj_returns.pkl\").iloc[1:]\n",
    "\n",
    "# drop_columns = []\n",
    "# for col in df.columns:\n",
    "#     if df[col].isnull().all() == True:\n",
    "#         drop_columns.append(col)\n",
    "        \n",
    "# df.drop(columns=drop_columns, inplace=True)\n",
    "\n",
    "# df['pct_change'] = df.close.pct_change()\n",
    "# df['log_ret'] = np.log(df.close) - np.log(df.close.shift(1))\n",
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.dropna(how='any',axis=0) #All rows have NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>905270</th>\n",
       "      <th>921795</th>\n",
       "      <th>904261</th>\n",
       "      <th>905261</th>\n",
       "      <th>916328</th>\n",
       "      <th>923024</th>\n",
       "      <th>936365</th>\n",
       "      <th>902355</th>\n",
       "      <th>912215</th>\n",
       "      <th>929813</th>\n",
       "      <th>...</th>\n",
       "      <th>9660J1</th>\n",
       "      <th>69568X</th>\n",
       "      <th>543755</th>\n",
       "      <th>77463M</th>\n",
       "      <th>29235J</th>\n",
       "      <th>131745</th>\n",
       "      <th>69487D</th>\n",
       "      <th>68157P</th>\n",
       "      <th>9110RA</th>\n",
       "      <th>292703</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.073424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.026594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042002</td>\n",
       "      <td>0.042352</td>\n",
       "      <td>-0.007893</td>\n",
       "      <td>-0.034946</td>\n",
       "      <td>-0.006981</td>\n",
       "      <td>0.025437</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>-0.034570</td>\n",
       "      <td>0.045914</td>\n",
       "      <td>-0.023507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.041516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.023492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045774</td>\n",
       "      <td>-0.040381</td>\n",
       "      <td>-0.029872</td>\n",
       "      <td>-0.042776</td>\n",
       "      <td>-0.034353</td>\n",
       "      <td>-0.047507</td>\n",
       "      <td>-0.041449</td>\n",
       "      <td>-0.032225</td>\n",
       "      <td>-0.001858</td>\n",
       "      <td>-0.073776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.133718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018214</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>-0.041720</td>\n",
       "      <td>0.014670</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>-0.030298</td>\n",
       "      <td>0.008515</td>\n",
       "      <td>-0.039008</td>\n",
       "      <td>-0.103963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.114582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.030586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050278</td>\n",
       "      <td>-0.001888</td>\n",
       "      <td>-0.039754</td>\n",
       "      <td>-0.029330</td>\n",
       "      <td>-0.021043</td>\n",
       "      <td>-0.042413</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>-0.003118</td>\n",
       "      <td>-0.012079</td>\n",
       "      <td>0.010919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059837</td>\n",
       "      <td>-0.051037</td>\n",
       "      <td>-0.046412</td>\n",
       "      <td>-0.017292</td>\n",
       "      <td>-0.040496</td>\n",
       "      <td>-0.066158</td>\n",
       "      <td>-0.032654</td>\n",
       "      <td>-0.031242</td>\n",
       "      <td>-0.039250</td>\n",
       "      <td>-0.007592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            905270  921795  904261  905261    916328  923024    936365  \\\n",
       "date                                                                     \n",
       "2021-05-24     NaN     NaN     NaN     NaN -0.073424     NaN -0.026594   \n",
       "2021-05-25     NaN     NaN     NaN     NaN -0.041516     NaN -0.023492   \n",
       "2021-05-26     NaN     NaN     NaN     NaN -0.133718     NaN -0.022297   \n",
       "2021-05-27     NaN     NaN     NaN     NaN -0.114582     NaN -0.030586   \n",
       "2021-05-28     NaN     NaN     NaN     NaN -0.046110     NaN  0.001882   \n",
       "\n",
       "            902355  912215  929813  ...    9660J1    69568X    543755  \\\n",
       "date                                ...                                 \n",
       "2021-05-24     NaN     NaN     NaN  ... -0.042002  0.042352 -0.007893   \n",
       "2021-05-25     NaN     NaN     NaN  ... -0.045774 -0.040381 -0.029872   \n",
       "2021-05-26     NaN     NaN     NaN  ... -0.018214  0.006846 -0.041720   \n",
       "2021-05-27     NaN     NaN     NaN  ... -0.050278 -0.001888 -0.039754   \n",
       "2021-05-28     NaN     NaN     NaN  ... -0.059837 -0.051037 -0.046412   \n",
       "\n",
       "              77463M    29235J    131745    69487D    68157P    9110RA  \\\n",
       "date                                                                     \n",
       "2021-05-24 -0.034946 -0.006981  0.025437  0.006211 -0.034570  0.045914   \n",
       "2021-05-25 -0.042776 -0.034353 -0.047507 -0.041449 -0.032225 -0.001858   \n",
       "2021-05-26  0.014670  0.006996  0.050378 -0.030298  0.008515 -0.039008   \n",
       "2021-05-27 -0.029330 -0.021043 -0.042413 -0.000474 -0.003118 -0.012079   \n",
       "2021-05-28 -0.017292 -0.040496 -0.066158 -0.032654 -0.031242 -0.039250   \n",
       "\n",
       "              292703  \n",
       "date                  \n",
       "2021-05-24 -0.023507  \n",
       "2021-05-25 -0.073776  \n",
       "2021-05-26 -0.103963  \n",
       "2021-05-27  0.010919  \n",
       "2021-05-28 -0.007592  \n",
       "\n",
       "[5 rows x 1237 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "train = tts[0]\n",
    "test = tts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>905270</th>\n",
       "      <th>921795</th>\n",
       "      <th>904261</th>\n",
       "      <th>905261</th>\n",
       "      <th>916328</th>\n",
       "      <th>923024</th>\n",
       "      <th>936365</th>\n",
       "      <th>902355</th>\n",
       "      <th>912215</th>\n",
       "      <th>929813</th>\n",
       "      <th>...</th>\n",
       "      <th>9660J1</th>\n",
       "      <th>69568X</th>\n",
       "      <th>543755</th>\n",
       "      <th>77463M</th>\n",
       "      <th>29235J</th>\n",
       "      <th>131745</th>\n",
       "      <th>69487D</th>\n",
       "      <th>68157P</th>\n",
       "      <th>9110RA</th>\n",
       "      <th>292703</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.163675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.026913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034316</td>\n",
       "      <td>-0.034879</td>\n",
       "      <td>0.028055</td>\n",
       "      <td>-0.082390</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>-0.082348</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>-0.008729</td>\n",
       "      <td>-0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.043404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.032232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.044945</td>\n",
       "      <td>-0.048701</td>\n",
       "      <td>-0.024175</td>\n",
       "      <td>0.036372</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>-0.017761</td>\n",
       "      <td>-0.005717</td>\n",
       "      <td>-0.040560</td>\n",
       "      <td>-0.020432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.077929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.063761</td>\n",
       "      <td>-0.033405</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>-0.025647</td>\n",
       "      <td>-0.015815</td>\n",
       "      <td>0.007270</td>\n",
       "      <td>0.020096</td>\n",
       "      <td>-0.031338</td>\n",
       "      <td>0.086688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.053374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.117544</td>\n",
       "      <td>0.022716</td>\n",
       "      <td>-0.024158</td>\n",
       "      <td>-0.015127</td>\n",
       "      <td>-0.021643</td>\n",
       "      <td>-0.004011</td>\n",
       "      <td>-0.016497</td>\n",
       "      <td>-0.020532</td>\n",
       "      <td>-0.026762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.027549</td>\n",
       "      <td>-0.066431</td>\n",
       "      <td>0.005881</td>\n",
       "      <td>-0.037008</td>\n",
       "      <td>-0.060536</td>\n",
       "      <td>-0.061752</td>\n",
       "      <td>-0.035843</td>\n",
       "      <td>-0.028278</td>\n",
       "      <td>-0.072243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            905270  921795  904261  905261    916328  923024    936365  \\\n",
       "date                                                                     \n",
       "2015-02-09     NaN     NaN     NaN     NaN -0.163675     NaN -0.026913   \n",
       "2015-02-10     NaN     NaN     NaN     NaN -0.043404     NaN -0.032232   \n",
       "2015-02-11     NaN     NaN     NaN     NaN -0.077929     NaN -0.016328   \n",
       "2015-02-12     NaN     NaN     NaN     NaN -0.053374     NaN -0.005984   \n",
       "2015-02-13     NaN     NaN     NaN     NaN -0.002998     NaN -0.016736   \n",
       "\n",
       "            902355  912215  929813  ...  9660J1    69568X    543755    77463M  \\\n",
       "date                                ...                                         \n",
       "2015-02-09     NaN     NaN     NaN  ...     NaN -0.034316 -0.034879  0.028055   \n",
       "2015-02-10     NaN     NaN     NaN  ...     NaN -0.044945 -0.048701 -0.024175   \n",
       "2015-02-11     NaN     NaN     NaN  ...     NaN -0.063761 -0.033405  0.003297   \n",
       "2015-02-12     NaN     NaN     NaN  ...     NaN -0.117544  0.022716 -0.024158   \n",
       "2015-02-13     NaN     NaN     NaN  ...     NaN -0.027549 -0.066431  0.005881   \n",
       "\n",
       "              29235J    131745    69487D    68157P    9110RA    292703  \n",
       "date                                                                    \n",
       "2015-02-09 -0.082390  0.014152 -0.082348  0.000718 -0.008729 -0.090909  \n",
       "2015-02-10  0.036372 -0.002761 -0.017761 -0.005717 -0.040560 -0.020432  \n",
       "2015-02-11 -0.025647 -0.015815  0.007270  0.020096 -0.031338  0.086688  \n",
       "2015-02-12 -0.015127 -0.021643 -0.004011 -0.016497 -0.020532 -0.026762  \n",
       "2015-02-13 -0.037008 -0.060536 -0.061752 -0.035843 -0.028278 -0.072243  \n",
       "\n",
       "[5 rows x 1237 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>905270</th>\n",
       "      <th>921795</th>\n",
       "      <th>904261</th>\n",
       "      <th>905261</th>\n",
       "      <th>916328</th>\n",
       "      <th>923024</th>\n",
       "      <th>936365</th>\n",
       "      <th>902355</th>\n",
       "      <th>912215</th>\n",
       "      <th>929813</th>\n",
       "      <th>...</th>\n",
       "      <th>9660J1</th>\n",
       "      <th>69568X</th>\n",
       "      <th>543755</th>\n",
       "      <th>77463M</th>\n",
       "      <th>29235J</th>\n",
       "      <th>131745</th>\n",
       "      <th>69487D</th>\n",
       "      <th>68157P</th>\n",
       "      <th>9110RA</th>\n",
       "      <th>292703</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.073424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.026594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042002</td>\n",
       "      <td>0.042352</td>\n",
       "      <td>-0.007893</td>\n",
       "      <td>-0.034946</td>\n",
       "      <td>-0.006981</td>\n",
       "      <td>0.025437</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>-0.034570</td>\n",
       "      <td>0.045914</td>\n",
       "      <td>-0.023507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.041516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.023492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045774</td>\n",
       "      <td>-0.040381</td>\n",
       "      <td>-0.029872</td>\n",
       "      <td>-0.042776</td>\n",
       "      <td>-0.034353</td>\n",
       "      <td>-0.047507</td>\n",
       "      <td>-0.041449</td>\n",
       "      <td>-0.032225</td>\n",
       "      <td>-0.001858</td>\n",
       "      <td>-0.073776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.133718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018214</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>-0.041720</td>\n",
       "      <td>0.014670</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>-0.030298</td>\n",
       "      <td>0.008515</td>\n",
       "      <td>-0.039008</td>\n",
       "      <td>-0.103963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.114582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.030586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050278</td>\n",
       "      <td>-0.001888</td>\n",
       "      <td>-0.039754</td>\n",
       "      <td>-0.029330</td>\n",
       "      <td>-0.021043</td>\n",
       "      <td>-0.042413</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>-0.003118</td>\n",
       "      <td>-0.012079</td>\n",
       "      <td>0.010919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059837</td>\n",
       "      <td>-0.051037</td>\n",
       "      <td>-0.046412</td>\n",
       "      <td>-0.017292</td>\n",
       "      <td>-0.040496</td>\n",
       "      <td>-0.066158</td>\n",
       "      <td>-0.032654</td>\n",
       "      <td>-0.031242</td>\n",
       "      <td>-0.039250</td>\n",
       "      <td>-0.007592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            905270  921795  904261  905261    916328  923024    936365  \\\n",
       "date                                                                     \n",
       "2021-05-24     NaN     NaN     NaN     NaN -0.073424     NaN -0.026594   \n",
       "2021-05-25     NaN     NaN     NaN     NaN -0.041516     NaN -0.023492   \n",
       "2021-05-26     NaN     NaN     NaN     NaN -0.133718     NaN -0.022297   \n",
       "2021-05-27     NaN     NaN     NaN     NaN -0.114582     NaN -0.030586   \n",
       "2021-05-28     NaN     NaN     NaN     NaN -0.046110     NaN  0.001882   \n",
       "\n",
       "            902355  912215  929813  ...    9660J1    69568X    543755  \\\n",
       "date                                ...                                 \n",
       "2021-05-24     NaN     NaN     NaN  ... -0.042002  0.042352 -0.007893   \n",
       "2021-05-25     NaN     NaN     NaN  ... -0.045774 -0.040381 -0.029872   \n",
       "2021-05-26     NaN     NaN     NaN  ... -0.018214  0.006846 -0.041720   \n",
       "2021-05-27     NaN     NaN     NaN  ... -0.050278 -0.001888 -0.039754   \n",
       "2021-05-28     NaN     NaN     NaN  ... -0.059837 -0.051037 -0.046412   \n",
       "\n",
       "              77463M    29235J    131745    69487D    68157P    9110RA  \\\n",
       "date                                                                     \n",
       "2021-05-24 -0.034946 -0.006981  0.025437  0.006211 -0.034570  0.045914   \n",
       "2021-05-25 -0.042776 -0.034353 -0.047507 -0.041449 -0.032225 -0.001858   \n",
       "2021-05-26  0.014670  0.006996  0.050378 -0.030298  0.008515 -0.039008   \n",
       "2021-05-27 -0.029330 -0.021043 -0.042413 -0.000474 -0.003118 -0.012079   \n",
       "2021-05-28 -0.017292 -0.040496 -0.066158 -0.032654 -0.031242 -0.039250   \n",
       "\n",
       "              292703  \n",
       "date                  \n",
       "2021-05-24 -0.023507  \n",
       "2021-05-25 -0.073776  \n",
       "2021-05-26 -0.103963  \n",
       "2021-05-27  0.010919  \n",
       "2021-05-28 -0.007592  \n",
       "\n",
       "[5 rows x 1237 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "# sc = MinMaxScaler(feature_range = (0, 1))\n",
    "# training_set_scaled = sc.fit_transform(train)\n",
    "# test_set_scaled = sc.fit_transform(test)\n",
    "# pd.DataFrame(training_set_scaled).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple multi-layer percepetron (MLP) autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1238)]            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 3717      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1238)              4952      \n",
      "=================================================================\n",
      "Total params: 8,669\n",
      "Trainable params: 8,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/250\n",
      "7/7 [==============================] - 1s 53ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/250\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/250\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/250\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/250\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/250\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/250\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/250\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/250\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/250\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/250\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/250\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/250\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/250\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/250\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/250\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/250\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/250\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/250\n",
      "7/7 [==============================] - 0s 31ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/250\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/250\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/250\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/250\n",
      "7/7 [==============================] - 0s 32ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/250\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/250\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/250\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/250\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/250\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/250\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/250\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/250\n",
      "7/7 [==============================] - 0s 32ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/250\n",
      "7/7 [==============================] - 0s 43ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/250\n",
      "7/7 [==============================] - 0s 29ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/250\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 101/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 102/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 103/250\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - val_loss: nan\n",
      "Epoch 104/250\n",
      "7/7 [==============================] - 0s 27ms/step - loss: nan - val_loss: nan\n",
      "Epoch 105/250\n",
      "7/7 [==============================] - 0s 27ms/step - loss: nan - val_loss: nan\n",
      "Epoch 106/250\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 107/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 108/250\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - val_loss: nan\n",
      "Epoch 109/250\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - val_loss: nan\n",
      "Epoch 110/250\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
      "Epoch 111/250\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - val_loss: nan\n",
      "Epoch 112/250\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 113/250\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 114/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 115/250\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 116/250\n",
      "7/7 [==============================] - 0s 34ms/step - loss: nan - val_loss: nan\n",
      "Epoch 117/250\n",
      "7/7 [==============================] - 0s 28ms/step - loss: nan - val_loss: nan\n",
      "Epoch 118/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 119/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 120/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 121/250\n",
      "7/7 [==============================] - 0s 28ms/step - loss: nan - val_loss: nan\n",
      "Epoch 122/250\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 123/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 124/250\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
      "Epoch 125/250\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
      "Epoch 126/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 127/250\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 128/250\n",
      "7/7 [==============================] - 0s 42ms/step - loss: nan - val_loss: nan\n",
      "Epoch 129/250\n",
      "7/7 [==============================] - 0s 28ms/step - loss: nan - val_loss: nan\n",
      "Epoch 130/250\n",
      "7/7 [==============================] - 0s 27ms/step - loss: nan - val_loss: nan\n",
      "Epoch 131/250\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 132/250\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 133/250\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 134/250\n",
      "7/7 [==============================] - 0s 27ms/step - loss: nan - val_loss: nan\n",
      "Epoch 135/250\n",
      "7/7 [==============================] - 0s 30ms/step - loss: nan - val_loss: nan\n",
      "Epoch 136/250\n",
      "7/7 [==============================] - 0s 28ms/step - loss: nan - val_loss: nan\n",
      "Epoch 137/250\n",
      "7/7 [==============================] - 0s 48ms/step - loss: nan - val_loss: nan\n",
      "Epoch 138/250\n",
      "7/7 [==============================] - 0s 36ms/step - loss: nan - val_loss: nan\n",
      "Epoch 139/250\n",
      "7/7 [==============================] - 0s 31ms/step - loss: nan - val_loss: nan\n",
      "Epoch 140/250\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - val_loss: nan\n",
      "Epoch 141/250\n",
      "7/7 [==============================] - 0s 27ms/step - loss: nan - val_loss: nan\n",
      "Epoch 142/250\n",
      "7/7 [==============================] - 0s 31ms/step - loss: nan - val_loss: nan\n",
      "Epoch 143/250\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
      "Epoch 144/250\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 145/250\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 146/250\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - val_loss: nan\n",
      "Epoch 147/250\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 148/250\n",
      "7/7 [==============================] - 0s 33ms/step - loss: nan - val_loss: nan\n",
      "Epoch 149/250\n",
      "7/7 [==============================] - 0s 51ms/step - loss: nan - val_loss: nan\n",
      "Epoch 150/250\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 151/250\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
      "Epoch 152/250\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - val_loss: nan\n",
      "Epoch 153/250\n",
      "7/7 [==============================] - 0s 33ms/step - loss: nan - val_loss: nan\n",
      "Epoch 154/250\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
      "Epoch 155/250\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - val_loss: nan\n",
      "Epoch 156/250\n",
      "7/7 [==============================] - 0s 34ms/step - loss: nan - val_loss: nan\n",
      "Epoch 157/250\n",
      "7/7 [==============================] - 0s 31ms/step - loss: nan - val_loss: nan\n",
      "Epoch 158/250\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 159/250\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 160/250\n",
      "7/7 [==============================] - 0s 33ms/step - loss: nan - val_loss: nan\n",
      "Epoch 161/250\n",
      "7/7 [==============================] - 0s 27ms/step - loss: nan - val_loss: nan\n",
      "Epoch 162/250\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - val_loss: nan\n",
      "Epoch 163/250\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 164/250\n",
      "7/7 [==============================] - 0s 37ms/step - loss: nan - val_loss: nan\n",
      "Epoch 165/250\n",
      "7/7 [==============================] - 0s 37ms/step - loss: nan - val_loss: nan\n",
      "Epoch 166/250\n",
      "7/7 [==============================] - 0s 33ms/step - loss: nan - val_loss: nan\n",
      "Epoch 167/250\n",
      "7/7 [==============================] - 0s 30ms/step - loss: nan - val_loss: nan\n",
      "Epoch 168/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 33ms/step - loss: nan - val_loss: nan\n",
      "Epoch 169/250\n",
      "7/7 [==============================] - 0s 35ms/step - loss: nan - val_loss: nan\n",
      "Epoch 170/250\n",
      "7/7 [==============================] - 0s 27ms/step - loss: nan - val_loss: nan\n",
      "Epoch 171/250\n",
      "7/7 [==============================] - 0s 30ms/step - loss: nan - val_loss: nan\n",
      "Epoch 172/250\n",
      "7/7 [==============================] - 0s 30ms/step - loss: nan - val_loss: nan\n",
      "Epoch 173/250\n",
      "7/7 [==============================] - 0s 43ms/step - loss: nan - val_loss: nan\n",
      "Epoch 174/250\n",
      "7/7 [==============================] - 0s 42ms/step - loss: nan - val_loss: nan\n",
      "Epoch 175/250\n",
      "7/7 [==============================] - 0s 27ms/step - loss: nan - val_loss: nan\n",
      "Epoch 176/250\n",
      "7/7 [==============================] - 0s 28ms/step - loss: nan - val_loss: nan\n",
      "Epoch 177/250\n",
      "7/7 [==============================] - 0s 37ms/step - loss: nan - val_loss: nan\n",
      "Epoch 178/250\n",
      "7/7 [==============================] - 0s 29ms/step - loss: nan - val_loss: nan\n",
      "Epoch 179/250\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 180/250\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 181/250\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 182/250\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - val_loss: nan\n",
      "Epoch 183/250\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 184/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 185/250\n",
      "7/7 [==============================] - 0s 30ms/step - loss: nan - val_loss: nan\n",
      "Epoch 186/250\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 187/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 188/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 189/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 190/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 191/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 192/250\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 193/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 194/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 195/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 196/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 197/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 198/250\n",
      "7/7 [==============================] - 0s 31ms/step - loss: nan - val_loss: nan\n",
      "Epoch 199/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 200/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 201/250\n",
      "7/7 [==============================] - 0s 39ms/step - loss: nan - val_loss: nan\n",
      "Epoch 202/250\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 203/250\n",
      "7/7 [==============================] - 0s 28ms/step - loss: nan - val_loss: nan\n",
      "Epoch 204/250\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 205/250\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - val_loss: nan\n",
      "Epoch 206/250\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 207/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 208/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 209/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 210/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 211/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 212/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 213/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 214/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 215/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 216/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 217/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 218/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 219/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 220/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 221/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 222/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 223/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 224/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 225/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 226/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 227/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 228/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 229/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 230/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 231/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 232/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 233/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 234/250\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 235/250\n",
      "7/7 [==============================] - 0s 32ms/step - loss: nan - val_loss: nan\n",
      "Epoch 236/250\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 237/250\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 238/250\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - val_loss: nan\n",
      "Epoch 239/250\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - val_loss: nan\n",
      "Epoch 240/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 241/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 242/250\n",
      "7/7 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 243/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 244/250\n",
      "7/7 [==============================] - 0s 28ms/step - loss: nan - val_loss: nan\n",
      "Epoch 245/250\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 246/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 247/250\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 248/250\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - val_loss: nan\n",
      "Epoch 249/250\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 250/250\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "# calculated log returns (i.e. the log of the difference between the price x+1 and price x)\n",
    "# windows of train.shape[1] consecutive returns will be produced. \n",
    "# Can be normalized with a MinMaxScaler to the range [0,1]??\n",
    "\n",
    "window_length = training_set_scaled.shape[1]\n",
    "encoding_dim = 3\n",
    "epochs = 250\n",
    "\n",
    "# compress the input to a 3-dimensional latent space.\n",
    "# the input and output of the autoencoder for 10 randomly selected price return windows extracted \n",
    "# from the test dataset  \n",
    "\n",
    "# input placeholder\n",
    "input_window = Input(shape=(window_length,))\n",
    "# encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_window) #tanh, linear, leakyrelu\n",
    "# lossy reconstruction of the input\n",
    "decoded = Dense(window_length, activation='linear')(encoded) #linear\n",
    "\n",
    "# model mapping an input to its reconstruction\n",
    "autoencoder = Model(input_window, decoded)\n",
    "\n",
    "# model mapping an input to its encoded representation\n",
    "encoder = Model(input_window, encoded)\n",
    "\n",
    "\n",
    "autoencoder.summary()\n",
    "autoencoder.compile(optimizer='adam', loss='MeanSquaredError') #MSE\n",
    "history = autoencoder.fit(training_set_scaled, training_set_scaled,\n",
    "                epochs=epochs,\n",
    "                batch_size=1024,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_set_scaled, test_set_scaled))\n",
    "\n",
    "decoded_stocks = autoencoder.predict(test_set_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1583 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1   2\n",
       "0    NaN NaN NaN\n",
       "1    NaN NaN NaN\n",
       "2    NaN NaN NaN\n",
       "3    NaN NaN NaN\n",
       "4    NaN NaN NaN\n",
       "...   ..  ..  ..\n",
       "1578 NaN NaN NaN\n",
       "1579 NaN NaN NaN\n",
       "1580 NaN NaN NaN\n",
       "1581 NaN NaN NaN\n",
       "1582 NaN NaN NaN\n",
       "\n",
       "[1583 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(encoder.predict(test_set_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1228</th>\n",
       "      <th>1229</th>\n",
       "      <th>1230</th>\n",
       "      <th>1231</th>\n",
       "      <th>1232</th>\n",
       "      <th>1233</th>\n",
       "      <th>1234</th>\n",
       "      <th>1235</th>\n",
       "      <th>1236</th>\n",
       "      <th>1237</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1583 rows × 1238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  1228  \\\n",
       "0      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "1      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "2      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "3      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "4      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "1578   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "1579   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "1580   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "1581   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "1582   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "\n",
       "      1229  1230  1231  1232  1233  1234  1235  1236  1237  \n",
       "0      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "1578   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1579   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1580   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1581   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1582   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[1583 rows x 1238 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(decoded_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"loss\"])\n",
    "    plt.title(\"Train loss\")\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "    plt.title(\"Test loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs Epoch\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D convolutional autoencoder\n",
    "(Kernel size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main “event” very well represented while the overall reconstruction is very smooth \n",
    "\n",
    "input_window = Input(shape=(window_length,1))\n",
    "x = Conv1D(16, 3, activation=\"tanh\", padding=\"same\")(input_window) # 10 dims\n",
    "#x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(2, padding=\"same\")(x) # 5 dims\n",
    "x = Conv1D(1, 3, activation=\"tanh\", padding=\"same\")(x) # 5 dims\n",
    "#x = BatchNormalization()(x)\n",
    "encoded = MaxPooling1D(2, padding=\"same\")(x) # 3 dims\n",
    "\n",
    "encoder = Model(input_window, encoded)\n",
    "\n",
    "# 3 dimensions in the encoded layer\n",
    "\n",
    "x = Conv1D(1, 3, activation=\"tanh\", padding=\"same\")(encoded) # 3 dims\n",
    "#x = BatchNormalization()(x)\n",
    "x = UpSampling1D(2)(x) # 6 dims\n",
    "x = Conv1D(16, 2, activation='tanh')(x) # 5 dims\n",
    "#x = BatchNormalization()(x)\n",
    "x = UpSampling1D(2)(x) # 10 dims\n",
    "decoded = Conv1D(1, 3, activation='linear', padding='same')(x) # 10 dims\n",
    "autoencoder = Model(input_window, decoded)\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='MeanSquaredError')\n",
    "history = autoencoder.fit(x_train, x_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=1024,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "decoded_stocks = autoencoder.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
