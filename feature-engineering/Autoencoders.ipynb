{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow._api.v2.compat.v1 as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>roc</th>\n",
       "      <th>rsi</th>\n",
       "      <th>tsi</th>\n",
       "      <th>bb_bbhi</th>\n",
       "      <th>bb_bbli</th>\n",
       "      <th>aroon_down</th>\n",
       "      <th>aroon</th>\n",
       "      <th>aroon_up</th>\n",
       "      <th>...</th>\n",
       "      <th>ema_30</th>\n",
       "      <th>ema_60</th>\n",
       "      <th>obv</th>\n",
       "      <th>vpt</th>\n",
       "      <th>fi</th>\n",
       "      <th>nvi</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-07-25</th>\n",
       "      <td>37.6250</td>\n",
       "      <td>27743.9</td>\n",
       "      <td>4.152249</td>\n",
       "      <td>43.173187</td>\n",
       "      <td>-14.062078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.695833</td>\n",
       "      <td>46.492968</td>\n",
       "      <td>-56541.9</td>\n",
       "      <td>-1139.157730</td>\n",
       "      <td>-629.318075</td>\n",
       "      <td>659.593185</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-26</th>\n",
       "      <td>36.0625</td>\n",
       "      <td>15452.1</td>\n",
       "      <td>2.852050</td>\n",
       "      <td>40.134541</td>\n",
       "      <td>-15.064725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.264583</td>\n",
       "      <td>46.095052</td>\n",
       "      <td>-71994.0</td>\n",
       "      <td>-1447.166569</td>\n",
       "      <td>-3988.544957</td>\n",
       "      <td>632.201442</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-27</th>\n",
       "      <td>31.3750</td>\n",
       "      <td>23576.7</td>\n",
       "      <td>-5.283019</td>\n",
       "      <td>32.699086</td>\n",
       "      <td>-18.375261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.762500</td>\n",
       "      <td>45.682552</td>\n",
       "      <td>-95570.7</td>\n",
       "      <td>-3706.260897</td>\n",
       "      <td>-19206.721570</td>\n",
       "      <td>632.201442</td>\n",
       "      <td>-0.587785</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-28</th>\n",
       "      <td>30.0000</td>\n",
       "      <td>12444.2</td>\n",
       "      <td>-14.438503</td>\n",
       "      <td>30.891204</td>\n",
       "      <td>-21.659706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.218750</td>\n",
       "      <td>45.280468</td>\n",
       "      <td>-108014.9</td>\n",
       "      <td>-3609.925738</td>\n",
       "      <td>-18907.300632</td>\n",
       "      <td>604.495403</td>\n",
       "      <td>-0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-31</th>\n",
       "      <td>30.1250</td>\n",
       "      <td>9478.4</td>\n",
       "      <td>-13.928571</td>\n",
       "      <td>31.263266</td>\n",
       "      <td>-24.163073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.689583</td>\n",
       "      <td>44.864843</td>\n",
       "      <td>-98536.5</td>\n",
       "      <td>-505.870013</td>\n",
       "      <td>-16037.000541</td>\n",
       "      <td>607.014133</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-24</th>\n",
       "      <td>3244.9900</td>\n",
       "      <td>2422.8</td>\n",
       "      <td>-1.856417</td>\n",
       "      <td>48.172664</td>\n",
       "      <td>-6.814223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3313.388000</td>\n",
       "      <td>3215.229000</td>\n",
       "      <td>1505136.7</td>\n",
       "      <td>-24.671503</td>\n",
       "      <td>-23573.005285</td>\n",
       "      <td>670.966455</td>\n",
       "      <td>-0.951057</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-25</th>\n",
       "      <td>3259.0500</td>\n",
       "      <td>3261.1</td>\n",
       "      <td>-0.989182</td>\n",
       "      <td>49.577056</td>\n",
       "      <td>-6.018646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3308.689667</td>\n",
       "      <td>3217.110833</td>\n",
       "      <td>1508397.8</td>\n",
       "      <td>45.830399</td>\n",
       "      <td>-13655.280816</td>\n",
       "      <td>670.966455</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-26</th>\n",
       "      <td>3265.1600</td>\n",
       "      <td>2384.0</td>\n",
       "      <td>2.340393</td>\n",
       "      <td>50.208486</td>\n",
       "      <td>-5.186664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3306.428333</td>\n",
       "      <td>3219.954667</td>\n",
       "      <td>1510781.8</td>\n",
       "      <td>18.599276</td>\n",
       "      <td>-9623.634985</td>\n",
       "      <td>672.224369</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-27</th>\n",
       "      <td>3230.1100</td>\n",
       "      <td>2561.2</td>\n",
       "      <td>0.192313</td>\n",
       "      <td>46.603165</td>\n",
       "      <td>-5.458353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3301.462333</td>\n",
       "      <td>3223.706500</td>\n",
       "      <td>1508220.6</td>\n",
       "      <td>-23.023837</td>\n",
       "      <td>-21073.124273</td>\n",
       "      <td>672.224369</td>\n",
       "      <td>-0.587785</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-28</th>\n",
       "      <td>3223.0700</td>\n",
       "      <td>2331.5</td>\n",
       "      <td>2.256705</td>\n",
       "      <td>45.890381</td>\n",
       "      <td>-5.877039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3295.583333</td>\n",
       "      <td>3227.798167</td>\n",
       "      <td>1505889.1</td>\n",
       "      <td>-32.574798</td>\n",
       "      <td>-20407.500805</td>\n",
       "      <td>670.759261</td>\n",
       "      <td>-0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5245 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                close   volume        roc        rsi        tsi  bb_bbhi  \\\n",
       "date                                                                       \n",
       "2000-07-25    37.6250  27743.9   4.152249  43.173187 -14.062078      0.0   \n",
       "2000-07-26    36.0625  15452.1   2.852050  40.134541 -15.064725      0.0   \n",
       "2000-07-27    31.3750  23576.7  -5.283019  32.699086 -18.375261      0.0   \n",
       "2000-07-28    30.0000  12444.2 -14.438503  30.891204 -21.659706      0.0   \n",
       "2000-07-31    30.1250   9478.4 -13.928571  31.263266 -24.163073      0.0   \n",
       "...               ...      ...        ...        ...        ...      ...   \n",
       "2021-05-24  3244.9900   2422.8  -1.856417  48.172664  -6.814223      0.0   \n",
       "2021-05-25  3259.0500   3261.1  -0.989182  49.577056  -6.018646      0.0   \n",
       "2021-05-26  3265.1600   2384.0   2.340393  50.208486  -5.186664      0.0   \n",
       "2021-05-27  3230.1100   2561.2   0.192313  46.603165  -5.458353      0.0   \n",
       "2021-05-28  3223.0700   2331.5   2.256705  45.890381  -5.877039      0.0   \n",
       "\n",
       "            bb_bbli  aroon_down  aroon  aroon_up  ...       ema_30  \\\n",
       "date                                              ...                \n",
       "2000-07-25      0.0        60.0  -56.0       4.0  ...    39.695833   \n",
       "2000-07-26      0.0        56.0  -52.0       4.0  ...    39.264583   \n",
       "2000-07-27      1.0       100.0  -36.0      64.0  ...    38.762500   \n",
       "2000-07-28      1.0       100.0  -40.0      60.0  ...    38.218750   \n",
       "2000-07-31      0.0        96.0  -40.0      56.0  ...    37.689583   \n",
       "...             ...         ...    ...       ...  ...          ...   \n",
       "2021-05-24      0.0        68.0  -36.0      32.0  ...  3313.388000   \n",
       "2021-05-25      0.0        64.0  -36.0      28.0  ...  3308.689667   \n",
       "2021-05-26      0.0        60.0  -36.0      24.0  ...  3306.428333   \n",
       "2021-05-27      0.0        56.0  -36.0      20.0  ...  3301.462333   \n",
       "2021-05-28      0.0        52.0  -36.0      16.0  ...  3295.583333   \n",
       "\n",
       "                 ema_60        obv          vpt            fi         nvi  \\\n",
       "date                                                                        \n",
       "2000-07-25    46.492968   -56541.9 -1139.157730   -629.318075  659.593185   \n",
       "2000-07-26    46.095052   -71994.0 -1447.166569  -3988.544957  632.201442   \n",
       "2000-07-27    45.682552   -95570.7 -3706.260897 -19206.721570  632.201442   \n",
       "2000-07-28    45.280468  -108014.9 -3609.925738 -18907.300632  604.495403   \n",
       "2000-07-31    44.864843   -98536.5  -505.870013 -16037.000541  607.014133   \n",
       "...                 ...        ...          ...           ...         ...   \n",
       "2021-05-24  3215.229000  1505136.7   -24.671503 -23573.005285  670.966455   \n",
       "2021-05-25  3217.110833  1508397.8    45.830399 -13655.280816  670.966455   \n",
       "2021-05-26  3219.954667  1510781.8    18.599276  -9623.634985  672.224369   \n",
       "2021-05-27  3223.706500  1508220.6   -23.023837 -21073.124273  672.224369   \n",
       "2021-05-28  3227.798167  1505889.1   -32.574798 -20407.500805  670.759261   \n",
       "\n",
       "             day_sin   day_cos  month_sin  month_cos  \n",
       "date                                                  \n",
       "2000-07-25 -0.866025  0.500000       -0.5  -0.866025  \n",
       "2000-07-26 -0.743145  0.669131       -0.5  -0.866025  \n",
       "2000-07-27 -0.587785  0.809017       -0.5  -0.866025  \n",
       "2000-07-28 -0.406737  0.913545       -0.5  -0.866025  \n",
       "2000-07-31  0.207912  0.978148       -0.5  -0.866025  \n",
       "...              ...       ...        ...        ...  \n",
       "2021-05-24 -0.951057  0.309017        0.5  -0.866025  \n",
       "2021-05-25 -0.866025  0.500000        0.5  -0.866025  \n",
       "2021-05-26 -0.743145  0.669131        0.5  -0.866025  \n",
       "2021-05-27 -0.587785  0.809017        0.5  -0.866025  \n",
       "2021-05-28 -0.406737  0.913545        0.5  -0.866025  \n",
       "\n",
       "[5245 rows x 34 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"amzn_cleaned\", index_col = 'date', parse_dates = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducedimension(input_, dimension = 3, learning_rate = 0.01, hidden_layer = 256, epoch = 100):\n",
    "    \n",
    "    input_size = input_.shape[1]\n",
    "    X = tf.placeholder(\"float\", [None, input_size])\n",
    "    \n",
    "    weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([input_size, hidden_layer])),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([hidden_layer, dimension])),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([dimension, hidden_layer])),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([hidden_layer, input_size])),\n",
    "    }\n",
    "    \n",
    "    biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([hidden_layer])),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([dimension])),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([hidden_layer])),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([input_size])),\n",
    "    }\n",
    "    \n",
    "    first_layer_encoder = tf.nn.sigmoid(tf.add(tf.matmul(X, weights['encoder_h1']), biases['encoder_b1']))\n",
    "    second_layer_encoder = tf.nn.sigmoid(tf.add(tf.matmul(first_layer_encoder, weights['encoder_h2']), biases['encoder_b2']))\n",
    "    first_layer_decoder = tf.nn.sigmoid(tf.add(tf.matmul(second_layer_encoder, weights['decoder_h1']), biases['decoder_b1']))\n",
    "    second_layer_decoder = tf.nn.sigmoid(tf.add(tf.matmul(first_layer_decoder, weights['decoder_h2']), biases['decoder_b2']))\n",
    "    cost = tf.reduce_mean(tf.pow(X - second_layer_decoder, 2))\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        last_time = time.time()\n",
    "        _, loss = sess.run([optimizer, cost], feed_dict={X: input_})\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print('epoch:', i + 1, 'loss:', loss, 'time:', time.time() - last_time)\n",
    "        \n",
    "    vectors = sess.run(second_layer_encoder, feed_dict={X: input_})\n",
    "    tf.reset_default_graph()\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py:1761: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 loss: 22456302000.0 time: 0.027853727340698242\n",
      "epoch: 20 loss: 22456302000.0 time: 0.036895036697387695\n",
      "epoch: 30 loss: 22456302000.0 time: 0.04354596138000488\n",
      "epoch: 40 loss: 22456302000.0 time: 0.02423691749572754\n",
      "epoch: 50 loss: 22456302000.0 time: 0.02950596809387207\n",
      "epoch: 60 loss: 22456302000.0 time: 0.026378870010375977\n",
      "epoch: 70 loss: 22456302000.0 time: 0.04195523262023926\n",
      "epoch: 80 loss: 22456302000.0 time: 0.03270983695983887\n",
      "epoch: 90 loss: 22456302000.0 time: 0.027720928192138672\n",
      "epoch: 100 loss: 22456302000.0 time: 0.026450157165527344\n"
     ]
    }
   ],
   "source": [
    "output = reducedimension(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5245, 3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 9.9990046e-01, 1.4646899e-07],\n",
       "       [1.0000000e+00, 9.9895555e-01, 1.6513322e-09],\n",
       "       [1.0000000e+00, 9.9993378e-01, 1.8470681e-08],\n",
       "       ...,\n",
       "       [4.1482747e-02, 9.9998617e-01, 9.9999547e-01],\n",
       "       [2.9538631e-02, 9.9997967e-01, 9.9999046e-01],\n",
       "       [2.9538631e-02, 9.9997967e-01, 9.9999046e-01]], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>1.464690e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998956</td>\n",
       "      <td>1.651332e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>1.847068e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999866</td>\n",
       "      <td>3.216791e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>3.097417e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>0.029539</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>9.999905e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>0.041483</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>9.999955e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5242</th>\n",
       "      <td>0.041483</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>9.999955e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5243</th>\n",
       "      <td>0.029539</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>9.999905e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244</th>\n",
       "      <td>0.029539</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>9.999905e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5245 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1             2\n",
       "0     1.000000  0.999900  1.464690e-07\n",
       "1     1.000000  0.998956  1.651332e-09\n",
       "2     1.000000  0.999934  1.847068e-08\n",
       "3     1.000000  0.999866  3.216791e-08\n",
       "4     1.000000  0.999842  3.097417e-09\n",
       "...        ...       ...           ...\n",
       "5240  0.029539  0.999980  9.999905e-01\n",
       "5241  0.041483  0.999986  9.999955e-01\n",
       "5242  0.041483  0.999986  9.999955e-01\n",
       "5243  0.029539  0.999980  9.999905e-01\n",
       "5244  0.029539  0.999980  9.999905e-01\n",
       "\n",
       "[5245 rows x 3 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_df = pd.DataFrame(output)\n",
    "ae_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_df.to_csv('autoencoded_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5245, 34), (4196, 3), (1049, 3))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 1049\n",
    "simulation_size = 1000\n",
    "df_train = ae_df.iloc[:-test_size]\n",
    "df_test = ae_df.iloc[-test_size:]\n",
    "df.shape, df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate,\n",
    "        num_layers,\n",
    "        size,\n",
    "        size_layer,\n",
    "        output_size,\n",
    "        forget_bias = 0.1,\n",
    "    ):\n",
    "        def lstm_cell(size_layer):\n",
    "            return tf.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)\n",
    "\n",
    "        rnn_cells = tf.compat.v1.nn.rnn_cell.MultiRNNCell(\n",
    "            [lstm_cell(size_layer) for _ in range(num_layers)],\n",
    "            state_is_tuple = False,\n",
    "        )\n",
    "        self.X = tf.placeholder(tf.float32, (None, None, size))\n",
    "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(\n",
    "            rnn_cells, output_keep_prob = forget_bias\n",
    "        )\n",
    "        self.hidden_layer = tf.placeholder(\n",
    "            tf.float32, (None, num_layers * 2 * size_layer)\n",
    "        )\n",
    "        self.outputs, self.last_state = tf.nn.dynamic_rnn(\n",
    "            drop, self.X, initial_state = self.hidden_layer, dtype = tf.float32\n",
    "        )\n",
    "        self.logits = tf.layers.dense(self.outputs[-1], output_size)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "            self.cost\n",
    "        )\n",
    "        \n",
    "def calculate_accuracy(real, predict):\n",
    "    real = np.array(real) + 1\n",
    "    predict = np.array(predict) + 1\n",
    "    percentage = 1 - np.sqrt(np.mean(np.square((real - predict) / real)))\n",
    "    return percentage * 100\n",
    "\n",
    "def anchor(signal, weight):\n",
    "    buffer = []\n",
    "    last = signal[0]\n",
    "    for i in signal:\n",
    "        smoothed_val = last * weight + (1 - weight) * i\n",
    "        buffer.append(smoothed_val)\n",
    "        last = smoothed_val\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "size_layer = 128\n",
    "timestamp = 5\n",
    "epoch = 300\n",
    "dropout_rate = 0.8\n",
    "future_day = test_size\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast():\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    modelnn = Model(\n",
    "        learning_rate, num_layers, ae_df.shape[1], size_layer, ae_df.shape[1], dropout_rate\n",
    "    )\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "\n",
    "    pbar = tqdm(range(epoch), desc = 'train loop')\n",
    "    for i in pbar:\n",
    "        init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "        total_loss, total_acc = [], []\n",
    "        for k in range(0, df_train.shape[0] - 1, timestamp):\n",
    "            index = min(k + timestamp, df_train.shape[0] - 1)\n",
    "            batch_x = np.expand_dims(\n",
    "                df_train.iloc[k : index, :].values, axis = 0\n",
    "            )\n",
    "            batch_y = df_train.iloc[k + 1 : index + 1, :].values\n",
    "            logits, last_state, _, loss = sess.run(\n",
    "                [modelnn.logits, modelnn.last_state, modelnn.optimizer, modelnn.cost],\n",
    "                feed_dict = {\n",
    "                    modelnn.X: batch_x,\n",
    "                    modelnn.Y: batch_y,\n",
    "                    modelnn.hidden_layer: init_value,\n",
    "                },\n",
    "            )        \n",
    "            init_value = last_state\n",
    "            total_loss.append(loss)\n",
    "            total_acc.append(calculate_accuracy(batch_y[:, 0], logits[:, 0]))\n",
    "        pbar.set_postfix(cost = np.mean(total_loss), acc = np.mean(total_acc))\n",
    "    \n",
    "    future_day = test_size\n",
    "\n",
    "    output_predict = np.zeros((df_train.shape[0] + future_day, df_train.shape[1]))\n",
    "    output_predict[0] = df_train.iloc[0]\n",
    "    upper_b = (df_train.shape[0] // timestamp) * timestamp\n",
    "    init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "\n",
    "    for k in range(0, (df_train.shape[0] // timestamp) * timestamp, timestamp):\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(\n",
    "                    df_train.iloc[k : k + timestamp], axis = 0\n",
    "                ),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[k + 1 : k + timestamp + 1] = out_logits\n",
    "\n",
    "    if upper_b != df_train.shape[0]:\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(df_train.iloc[upper_b:], axis = 0),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        output_predict[upper_b + 1 : df_train.shape[0] + 1] = out_logits\n",
    "        future_day -= 1\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "\n",
    "    init_value = last_state\n",
    "    \n",
    "    for i in range(future_day):\n",
    "        o = output_predict[-future_day - timestamp + i:-future_day + i]\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(o, axis = 0),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[-future_day + i] = out_logits[-1]\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "    \n",
    "    output_predict = minmax.inverse_transform(output_predict)\n",
    "    deep_future = anchor(output_predict[:, 0], 0.3)\n",
    "    \n",
    "    return deep_future[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 1\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.LSTMCell object at 0x7f924881e1c0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anjalichauhan/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:909: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.compat.v1' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-f5aa569f2292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'simulation %d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-142-edfa09ebcdb1>\u001b[0m in \u001b[0;36mforecast\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     modelnn = Model(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mae_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mae_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-140-b23faa8553ca>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, learning_rate, num_layers, size, size_layer, output_size, forget_bias)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         drop = tf.contrib.rnn.DropoutWrapper(\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mrnn_cells\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_keep_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforget_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.compat.v1' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(simulation_size):\n",
    "    print('simulation %d'%(i + 1))\n",
    "    results.append(forecast())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [calculate_accuracy(df['Close'].iloc[-test_size:].values, r) for r in results]\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "for no, r in enumerate(results):\n",
    "    plt.plot(r, label = 'forecast %d'%(no + 1))\n",
    "plt.plot(df['Close'].iloc[-test_size:].values, label = 'true trend', c = 'black')\n",
    "plt.legend()\n",
    "plt.title('average accuracy: %.4f'%(np.mean(accuracies)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
